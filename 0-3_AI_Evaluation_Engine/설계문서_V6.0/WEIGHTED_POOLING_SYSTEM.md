# 가중치 기반 데이터 풀링 시스템 (Weighted Data Pooling System)

## 문제 정의

### 기존 시스템의 한계

**AI별 순위 불일치 문제**:
- ChatGPT: 김동연 29위
- Grok: 김동연 4위
- Claude: 김동연 2위
- **순위 차이: 27위** (치명적 불일치)

**Pearson 상관계수**:
- Claude vs ChatGPT: -0.088 (상관 없음)
- Claude vs Grok: 0.195 (약한 상관)
- ChatGPT vs Grok: -0.242 (음의 상관)

### 근본 원인

**데이터 수집 편향 (Data Collection Bias)**:

각 AI가 서로 다른 뉴스를 수집:
- ChatGPT: 부정적 뉴스 선호 (64% PUBLIC, 스캔들 위주)
- Grok: 균형적 수집 (47% OFFICIAL, 53% PUBLIC)
- Claude: 긍정적 뉴스 선호 (51% B등급 집중)

**결과**: 동일 정치인에 대해 완전히 다른 데이터 기반 평가 → 순위 불일치

---

## 해결 방안: 가중치 기반 데이터 풀링 시스템

### 핵심 원리

**"중복 = 중요도"**

3개 AI가 독립적으로 동일한 뉴스를 수집했다면, 그 뉴스는 **객관적으로 중요한 사건**입니다.

### 시스템 구조

#### Step 1: 데이터 풀 생성

```
ChatGPT 수집 데이터: 50개
Grok 수집 데이터:    50개
Claude 수집 데이터:   50개
───────────────────────────
총 데이터 풀:        150개 (중복 포함)
```

**중복 제거하지 않음** ← 핵심 차별점

#### Step 2: 중복 탐지 및 그룹화

제목 유사도 기반으로 중복 탐지:

```
뉴스 A: "김동연 경제부총리 시절 GDP 3% 성장"
  - ChatGPT 수집 ✓
  - Grok 수집 ✓
  - Claude 수집 ✓
  → 중복 횟수: 3 (중요도 높음)

뉴스 B: "김동연의 청년배당 정책 논란"
  - ChatGPT 수집 ✓
  - Grok 수집 ✗
  - Claude 수집 ✗
  → 중복 횟수: 1 (중요도 보통)
```

#### Step 3: 대표 평가 (API 비용 절감)

**중복된 뉴스는 1번만 평가**:

```python
if is_duplicate(news):
    # 대표 1개만 AI에게 평가 요청
    rating = evaluate_once(news)

    # 중복된 모든 항목에 동일 등급 적용
    for duplicate_item in duplicates:
        duplicate_item.rating = rating
else:
    # 고유 뉴스는 개별 평가
    rating = evaluate(news)
```

**장점**:
- API 호출 최소화 (중복 건 재평가 안 함)
- 일관된 등급 적용 (같은 뉴스 = 같은 평가)

#### Step 4: 가중치 자동 반영

150개 데이터 풀에서 점수 계산:

```python
# 예시 데이터 풀 (150개)
뉴스 A (중복 3회): B등급 (6점) × 3개 = 18점 영향력
뉴스 B (중복 1회): A등급 (8점) × 1개 = 8점 영향력
뉴스 C (중복 2회): E등급 (-2점) × 2개 = -4점 영향력
...

# 최종 점수
평균 = sum(모든 150개 평가) / 150
```

**자연스러운 가중치**:
- 중복 횟수 = 자동 가중치
- 인위적 계산 불필요
- 중요 뉴스가 자동으로 더 큰 영향력

---

## 기대 효과

### 1. 순위 일관성 확보

**Before (현재)**:
```
ChatGPT: 각자 수집한 50개 데이터 → 29위
Grok:    각자 수집한 50개 데이터 → 4위
Claude:  각자 수집한 50개 데이터 → 2위
→ 27위 차이 (데이터 편향)
```

**After (풀링 시스템)**:
```
ChatGPT: 공통 150개 데이터 풀 → ?위
Grok:    공통 150개 데이터 풀 → ?위
Claude:  공통 150개 데이터 풀 → ?위
→ 순위 차이 최소화 (동일 데이터)
```

### 2. 객관성 향상

- **데이터 표준화**: 모든 AI가 동일한 뉴스 기반 평가
- **편향 제거**: 특정 AI의 수집 편향 무력화
- **중요도 반영**: 객관적으로 중요한 뉴스에 자동 가중치

### 3. 관점 차이 명확화

**점수 차이는 유지 가능**:
- Claude: 같은 뉴스에 긍정적 평가 → 높은 점수
- ChatGPT: 같은 뉴스에 보수적 평가 → 낮은 점수

**이것은 문제가 아님**:
- 각 AI의 고유한 관점 (교육 데이터 차이)
- 순위 일관성만 확보되면 OK

### 4. 학문적 타당성

**통계적 근거**:
- 샘플 크기: 150개 (충분한 표본)
- 대표성: 3개 독립 소스의 통합
- 가중치: 자연 발생적 (인위적 조작 없음)

**재현 가능성**:
- 동일 데이터 풀 → 동일 조건
- 평가 프로세스 투명
- 결과 검증 가능

---

## 구현 계획

### Phase 1: 테스트 (김동연)

1. **데이터 풀 생성**: Expertise 카테고리 150개
2. **중복 탐지**: 제목 유사도 > 90%
3. **대표 평가**: 고유 뉴스만 평가
4. **점수 계산**: 150개 전체 사용
5. **순위 비교**: 기존 vs 풀링 시스템

### Phase 2: 확장 (10개 카테고리)

- Expertise, Leadership, Vision, ... (10개 전체)
- 카테고리별 150개 데이터 풀
- 종합 점수 산출

### Phase 3: 전체 적용 (30명 정치인)

- 모든 정치인 재평가
- 순위 일관성 검증
- 최종 랭킹 확정

---

## 핵심 주장

### "중복 제거는 잘못된 접근이다"

**기존 접근 (잘못)**:
```
중복 뉴스 = 노이즈 → 제거해야 함
```

**우리의 접근 (올바름)**:
```
중복 뉴스 = 중요 신호 → 가중치 부여
```

### "가중치 기반 풀링이 해답이다"

1. **데이터 편향 제거**: 동일 데이터 풀 사용
2. **객관성 확보**: 중복 = 중요도
3. **순위 일관성**: 같은 데이터 → 일관된 순위
4. **관점 존중**: AI별 고유 관점 유지
5. **비용 효율**: 중복 건 재평가 안 함

---

## 결론

**순위 불일치의 근본 원인**은 데이터 수집 편향입니다.

**해결책**은 가중치 기반 데이터 풀링 시스템입니다:
- 150개 공통 데이터 풀
- 중복 유지 (자동 가중치)
- 대표 평가 (비용 절감)
- 순위 일관성 확보

**점수 차이는 문제가 아닙니다**. 각 AI의 고유한 관점이며, 순위 일관성만 확보되면 됩니다.

---

**작성일**: 2025-11-30
**버전**: V1.0
**담당**: AI Evaluation Engine Team
