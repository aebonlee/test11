# 설계문서_V6.0 - 정치인 평가 시스템 종합 문서

**작성일**: 2025-11-19
**버전**: V6.0 (V23.0 알고리즘 기반)
**상태**: 현행화 완료

---

## 📂 폴더 구조

```
설계문서_V6.0/
├── README_V6.0_종합.md                          ← 이 파일
├── CLAUDE_V6.0.md                               ← Claude Code 작업 지침
├── 메인에이전트_작업지침서.md                    ← DB 스키마 및 코딩 가이드
├── requirements.txt                              ← Python 패키지 목록
├── V8.0_작업지시서_전체_10개카테고리.md           ← 원본 종합 작업지시서 (38KB)
├── 46_V6.2_7개AI_종합분석_최종안.md               ← 학술 근거 및 평가 기준 (37KB)
├── 6_10개카테고리별커스텀설정.md                  ← 카테고리별 세부 설정 (21KB)
└── instructions/                                 ← V23.0 종합 Instruction 파일
    ├── category_1_expertise.md                  (12KB)
    ├── category_2_leadership.md                 (12KB)
    ├── category_3_vision.md                     (10KB)
    ├── category_4_integrity.md                  (10KB)
    ├── category_5_ethics.md                     (9.5KB)
    ├── category_6_accountability.md             (9.6KB)
    ├── category_7_transparency.md               (9.5KB)
    ├── category_8_communication.md              (9.4KB)
    ├── category_9_responsiveness.md             (9.5KB)
    └── category_10_publicinterest.md            (9.6KB)
```

---

## 🎯 V23.0 알고리즘 핵심 사양

### 1. 부정 주제 최소 20% 보장
- **목적**: 논란, 비판, 문제점 등 부정적 주제를 최소 20% 수집
- **중요**: 부정 주제를 수집하되, 각 내용은 객관적으로 평가
  - 경미한 논란 → C 또는 D 등급 (긍정)
  - 심각한 문제 → -B 또는 -A 등급 (부정)

### 2. PUBLIC/OFFICIAL 50:50 비중
- **PUBLIC (공개 출처)**: 50% 필수
  - 언론 보도, Wikipedia, 시민단체, SNS 등
- **OFFICIAL (공식 출처)**: 50% 필수
  - 중앙선관위, 국회의안정보, 감사원, 대법원 등

### 3. 8단계 알파벳 등급 시스템
- **긍정**: A(+8), B(+6), C(+4), D(+2)
- **부정**: -D(-2), -C(-4), -B(-6), -A(-8)

### 4. Prior 6.5 + Coefficient 0.5
```python
category_score = (6.5 + avg_rating × 0.5) × 10
final_score = sum(10개 카테고리 점수)
```
- **카테고리 점수 범위**: 25 ~ 105점
- **최종 점수 범위**: 250 ~ 1,000점

### 5. AI 모델
```python
MODEL = "claude-3-5-haiku-20241022"
```

---

## 📖 문서별 역할 및 사용법

### 1. CLAUDE_V6.0.md
**역할**: Claude Code 메인 에이전트 작업 지침
**내용**:
- V14.0 자동화 아키텍처
- 필수 참조 문서 목록
- 금지 사항
- 실행 가이드

**사용 시점**:
- 새로운 Claude Code 세션 시작 시 필수 확인
- 프로젝트 전체 방향성 확인 필요 시

---

### 2. 메인에이전트_작업지침서.md
**역할**: DB 스키마 및 코딩 작업 가이드
**내용**:
- DB 스키마 (Primary Key: `collected_data_id`)
- 절대 금지 사항 (`id`, `item_id` 사용 금지)
- 올바른 코드 작성 예시
- 표준 스크립트 템플릿

**사용 시점**:
- DB 쿼리 작성 전 필수 확인
- Python 스크립트 작성 전
- "column does not exist" 에러 발생 시

---

### 3. V8.0_작업지시서_전체_10개카테고리.md (38KB)
**역할**: 원본 종합 작업지시서 (가장 완전한 버전)
**내용**:
- PUBLIC/OFFICIAL 상세 정의 및 출처 목록
- 60% OFFICIAL / 40% PUBLIC 비중 규칙
- 10개 카테고리 상세 설명
- 평가 범위, 제외 범위
- 검색 키워드
- 측정 지표

**사용 시점**:
- Instruction 파일 생성/수정 시 참조
- 출처 유형 확인 필요 시
- 카테고리 정의 재확인 시

**주요 섹션**:
```markdown
### 【출처 정의】
#### 📊 공식 출처 (Official Data)
1. 선거관리위원회 (www.nec.go.kr)
2. 의안정보시스템 (likms.assembly.go.kr)
3. 정보공개포털 (www.open.go.kr)
...
13개 공식 출처 상세 설명

#### 🌐 공개 출처 (Public Data)
1. Wikipedia (ko.wikipedia.org)
2. 빅카인즈 (bigkinds.or.kr)
3. 시민단체 보고서 (참여연대, 경실련 등)
...
11개 공개 출처 상세 설명

### 【출처 비중 규칙】
📊 공식 출처 (Official Data): 60% 이상
🌐 공개 출처 (Public Data): 40% 이상
```

---

### 4. 46_V6.2_7개AI_종합분석_최종안.md (37KB)
**역할**: 학술 근거 및 평가 기준 종합 분석
**내용**:
- 7개 AI 모델의 평가 기준 합의 결과
- 학술 논문 근거 (Stoker 2024, Slough 2024, Volden & Wiseman 2024 등)
- 카테고리별 측정 지표
- 공식/공개 출처 비중

**사용 시점**:
- 학술적 근거 필요 시
- 평가 기준의 타당성 검증 시
- 논문 인용 필요 시

**주요 섹션**:
```markdown
### 분야 1: 전문성 (7개: 공식 4, 공개 3)

**1-1. 최종 학력 수준**
- **합의도**: 6/6 AI
- **측정**: 박사=3, 석사=2, 학사=1
- **출처**: 중앙선관위 후보자 정보
- **학술 근거**: Stoker et al. (2024), Volden & Wiseman (2025)
```

---

### 5. 6_10개카테고리별커스텀설정.md (21KB)
**역할**: 카테고리별 세부 커스텀 설정
**내용**:
- 카테고리별 핵심 평가 요소
- 검색 키워드 상세
- 함정 (Pitfalls)
- 수집 팁

**사용 시점**:
- 특정 카테고리 평가 전
- 검색 키워드 확인 시
- 평가 시 주의사항 확인 시

**주요 섹션**:
```markdown
## 카테고리 1: 전문성

### 【핵심 평가 요소】
1순위: 최고 학력
  +5: 서울대/연세대/고려대 등 명문대 + 대학원
  +4: 명문대 (국내/해외 상위권)
  ...

### 【검색 키워드】
- "{정치인명} 학력"
- "{정치인명} 학위"
...

### 【함정 (Pitfalls)】
1. 학벌 과대평가: 명문대 출신이라도 경력이 짧으면 C~D 등급
2. 경력 허수 구별: 명목상 경력 vs. 실질적 경력 구분
...
```

---

### 6. instructions/ 폴더 (V23.0 종합 Instruction)
**역할**: Claude API가 직접 참조하는 평가 지침서
**내용** (각 파일 9-12KB):
- V8.0 + V6.2 + V6.0 모든 내용 통합
- V23.0 부정 주제 20% 최소 보장
- V21.0 알파벳 등급 시스템 (A~-A)
- PUBLIC/OFFICIAL 50:50 비중
- 학술 근거
- 상세 평가 기준
- 검색 키워드
- 등급별 예시

**사용 시점**:
- Claude API 데이터 수집 시 자동 참조
- Instruction 파일 확인/수정 시

**파일 구조**:
```markdown
# Category 1: Expertise (전문성) - V23.0 Comprehensive

## 📋 V23.0 핵심 변경사항
- 부정 주제 최소 20% 보장
- PUBLIC/OFFICIAL 50:50 비중
- 8단계 알파벳 등급

## 🎯 카테고리 정의
- 한글 정의
- 영문 정의
- 학술 근거 (Stoker 2024, Slough 2024 등)

## 📊 출처 정의 및 비중
### OFFICIAL (50% 필수)
- 13개 공식 출처 상세 설명
### PUBLIC (50% 필수)
- 11개 공개 출처 상세 설명

## 🎯 V23.0 8단계 알파벳 등급 시스템
- A~-A 등급별 상세 설명 및 예시

## 📋 평가 범위
- 평가하는 것 / 평가하지 않는 것

## 🔍 검색 키워드
- 기본 검색어 / 부정 주제 검색어

## 📊 측정 지표
- 우선순위별 측정 기준

## ⚠️ 평가 시 주의사항
- 함정 (Pitfalls)
- 객관성 유지 원칙
```

---

## 🔄 문서 간 관계도

```
CLAUDE_V6.0.md (최상위 작업 지침)
    │
    ├─→ 메인에이전트_작업지침서.md (DB 스키마, 코딩 가이드)
    │
    ├─→ V8.0_작업지시서_전체_10개카테고리.md (원본 종합 지침)
    │       │
    │       ├─→ instructions/category_*.md (V23.0 종합 Instruction)
    │       │       │
    │       │       └─→ 46_V6.2_7개AI_종합분석_최종안.md (학술 근거)
    │       │       └─→ 6_10개카테고리별커스텀설정.md (세부 설정)
    │       │
    │       └─→ Claude API (데이터 수집 시 참조)
    │
    └─→ requirements.txt (Python 패키지)
```

---

## 📝 작업 흐름

### 1. 새로운 정치인 평가 시작
```bash
# 1) CLAUDE_V6.0.md 확인
# 2) 메인에이전트_작업지침서.md 확인
# 3) V23.0 수집 스크립트 실행
python collect_v23_min_negative.py \
    --politician_id=5 \
    --politician_name="오세훈"
```

### 2. Instruction 파일 수정 시
```bash
# 1) V8.0_작업지시서_전체_10개카테고리.md 참조
# 2) 46_V6.2_7개AI_종합분석_최종안.md 학술 근거 확인
# 3) 6_10개카테고리별커스텀설정.md 세부 설정 확인
# 4) instructions/category_*.md 수정
```

### 3. 새로운 알고리즘 버전 개발 시
```bash
# 1) CLAUDE_V6.0.md 버전 업데이트
# 2) instructions/ 폴더 내 파일 수정
# 3) 수집 스크립트 업데이트
# 4) 테스트 실행
```

---

## 🔍 빠른 검색 인덱스

### PUBLIC/OFFICIAL 정의 찾기
→ `V8.0_작업지시서_전체_10개카테고리.md` 섹션: 【출처 정의】

### 학술 근거 찾기
→ `46_V6.2_7개AI_종합분석_최종안.md` 각 카테고리 섹션

### 검색 키워드 찾기
→ `6_10개카테고리별커스텀설정.md` 각 카테고리 【검색 키워드】

### 등급 예시 찾기
→ `instructions/category_*.md` 섹션: V23.0 등급 선택 가이드라인

### DB 스키마 확인
→ `메인에이전트_작업지침서.md` 섹션: collected_data 테이블 Primary Key

### 코드 템플릿 찾기
→ `메인에이전트_작업지침서.md` 섹션: 표준 스크립트 템플릿

---

## 📊 버전 히스토리

### V23.0 (2025-11-19) - 현재 버전
- **핵심 변경**: 부정 주제 최소 20% 보장
- **이유**: V22.0에서 부정 주제가 0-24%로 너무 적게 수집됨
- **방법**: 논란/비판/문제점 등 부정 주제 수집 후 객관적 평가
- **주의**: 부정 주제 ≠ 부정 등급 (경미한 논란 → 긍정 등급 가능)

### V22.0 (2025-11-18)
- **핵심 변경**: 50:50 강제 제거, 자유 분포
- **문제**: 부정 주제가 너무 적게 수집됨 (0-24%)
- **교훈**: 완전 자유 분포는 AI의 긍정 편향으로 인해 불균형 발생

### V21.0 (2025-11-17)
- **핵심 변경**: 8단계 알파벳 등급 (A~-A)
- **이유**: 17단계에서 8단계로 단순화
- **문제**: 50:50 강제로 인해 600점 부근 집중

### V20.0 이전
- 17단계 등급 (-8~+8)
- 다양한 실험 (Prior 조정, Coefficient 조정 등)

---

## 🚨 중요 원칙 (절대 위반 금지)

### 1. DB 스키마
- ✅ Primary Key: `collected_data_id`
- ❌ 절대 사용 금지: `id`, `item_id`

### 2. 출처 비중
- ✅ PUBLIC 50% + OFFICIAL 50%
- ❌ 편향된 출처 사용 금지

### 3. 부정 주제 vs 부정 등급
- ✅ 부정 주제 수집 후 객관적 평가
- ❌ 부정 주제에 부정 등급 강제 금지

### 4. 알고리즘 고정
- ✅ Prior 6.5, Coefficient 0.5 유지
- ❌ 임의 변경 금지

### 5. 등급 범위
- ✅ A~-A (8단계) 사용
- ❌ 다른 등급 사용 금지

---

## 📞 문제 해결

### Q1: Instruction 파일이 너무 짧은 것 같습니다
**A**: V23.0 기준 각 파일은 9-12KB입니다. 이전 V22.0 이하 버전은 2.4KB로 불완전했습니다.
**확인**: `ls -lh instructions/` 실행하여 파일 크기 확인

### Q2: PUBLIC/OFFICIAL 정의를 찾을 수 없습니다
**A**: `V8.0_작업지시서_전체_10개카테고리.md` 파일의 【출처 정의】 섹션 참조

### Q3: DB 에러 "column id does not exist"
**A**: `메인에이전트_작업지침서.md` 확인. Primary Key는 `collected_data_id`

### Q4: 부정 주제를 수집했는데 긍정 등급이 나왔습니다
**A**: 정상입니다. 경미한 논란/비판은 C 또는 D 등급 (긍정)을 받을 수 있습니다.

### Q5: 학술 근거를 추가하고 싶습니다
**A**: `46_V6.2_7개AI_종합분석_최종안.md` 참조하여 instruction 파일에 추가

---

## 🎯 다음 단계

1. **데이터 수집 테스트**
   ```bash
   python collect_v23_min_negative.py \
       --politician_id=5 \
       --politician_name="오세훈" \
       --category=1
   ```

2. **결과 검증**
   - 부정 주제 20% 이상 확보 확인
   - PUBLIC/OFFICIAL 50:50 확인
   - 등급 분포 확인 (A/-A, B/-B 최소 20%)

3. **전체 10개 카테고리 수집**
   ```bash
   python collect_v23_min_negative.py \
       --politician_id=5 \
       --politician_name="오세훈"
   ```

4. **점수 계산**
   ```bash
   python calculate_scores_v23.py --politician_id=5
   ```

---

**최종 업데이트**: 2025-11-19
**버전**: V6.0 (V23.0 알고리즘 기반)
**작성자**: Claude Code
**상태**: ✅ 현행화 완료

**이 폴더는 정치인 평가 시스템의 모든 현행 문서를 포함합니다.**
