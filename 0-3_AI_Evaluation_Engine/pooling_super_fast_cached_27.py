"""
ì´ˆê³ ì† + ì´ˆì €ë¹„ìš© V24.5 Pooling í‰ê°€ ì‹œìŠ¤í…œ
í”„ë¡¬í”„íŠ¸ ìºì‹±ìœ¼ë¡œ í† í° ì‚¬ìš©ëŸ‰ 90% ì ˆê°

í•µì‹¬ ì „ëµ:
1. Claude Prompt Caching (ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ë‰´ìŠ¤ ë°ì´í„°)
2. ì²­í¬ ë°©ì‹ (30ê°œì”© 5ê°œ ì²­í¬)
3. ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ (3ê°œ AI ë™ì‹œ ì‹¤í–‰)

ì˜ˆìƒ ì„±ëŠ¥:
- ì‹œê°„: 1-2ì‹œê°„
- í† í°: ê¸°ì¡´ ëŒ€ë¹„ 90% ì ˆê°
"""

import asyncio
import aiohttp
import json
import os
from datetime import datetime
from typing import List, Dict
import anthropic
import openai

# API ì„¤ì •
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROK_API_KEY = os.getenv("XAI_API_KEY")

CATEGORIES = [
    "Expertise", "Leadership", "Vision", "Integrity", "Ethics",
    "Accountability", "Transparency", "Communication", "Responsiveness", "PublicInterest"
]

# TODO: ì‹¤ì œ ì •ì¹˜ì¸ ëª©ë¡ìœ¼ë¡œ êµì²´
REMAINING_POLITICIANS = [
    f"ì •ì¹˜ì¸{i}" for i in range(4, 31)  # 27ëª…
]


class CachedPoolingEvaluator:
    """í”„ë¡¬í”„íŠ¸ ìºì‹± ê¸°ë°˜ ì´ˆê³ ì† í‰ê°€ ì—”ì§„"""

    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        self.grok_api_key = GROK_API_KEY

        # í‰ê°€ ê¸°ì¤€ (ìºì‹±ìš©)
        self.evaluation_criteria = self._load_evaluation_criteria()

    def _load_evaluation_criteria(self) -> str:
        """í‰ê°€ ê¸°ì¤€ ë¡œë“œ (ìºì‹± ëŒ€ìƒ)"""
        return """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì •ì¹˜ì¸ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ 10ê°œ ê¸°ì¤€ìœ¼ë¡œ ì •ì¹˜ì¸ì„ í‰ê°€í•˜ì„¸ìš”:

1. **Expertise (ì „ë¬¸ì„±)**: ì •ì±… ì „ë¬¸ì„±, ë¶„ì•¼ ì§€ì‹, ê²½ë ¥
2. **Leadership (ë¦¬ë”ì‹­)**: ì¡°ì§ ê´€ë¦¬, ê²°ë‹¨ë ¥, ì¶”ì§„ë ¥
3. **Vision (ë¹„ì „)**: ë¯¸ë˜ ë¹„ì „, ì •ì±… ë°©í–¥ì„±, í˜ì‹ ì„±
4. **Integrity (ì²­ë ´ë„)**: ë¶€íŒ¨ ì—†ìŒ, ë„ë•ì„±, ì •ì§ì„±
5. **Ethics (ìœ¤ë¦¬ì„±)**: ìœ¤ë¦¬ì  íŒë‹¨, ê°€ì¹˜ê´€, ì›ì¹™
6. **Accountability (ì±…ì„ê°)**: ì•½ì† ì´í–‰, ì±…ì„ ì˜ì‹, ê²°ê³¼ ì±…ì„
7. **Transparency (íˆ¬ëª…ì„±)**: ì •ë³´ ê³µê°œ, íˆ¬ëª…í•œ ì˜ì‚¬ê²°ì •, ê³µê°œì„±
8. **Communication (ì†Œí†µëŠ¥ë ¥)**: êµ­ë¯¼ê³¼ì˜ ì†Œí†µ, ì„¤ëª… ëŠ¥ë ¥, ê²½ì²­
9. **Responsiveness (ëŒ€ì‘ì„±)**: ë¯¼ì› ëŒ€ì‘, ìœ„ê¸° ê´€ë¦¬, ì‹ ì†ì„±
10. **PublicInterest (ê³µìµì„±)**: ê³µê³µì˜ ì´ìµ ìš°ì„ , ì‚¬íšŒì  ê°€ì¹˜

í‰ê°€ ë°©ë²•:
- ê° ë‰´ìŠ¤ì—ì„œ ì •ì¹˜ì¸ì˜ í–‰ë™/ë°œì–¸ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„
- ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ 0-100ì  ì ìˆ˜ ë¶€ì—¬
- ê¸ì •ì  í–‰ë™: ë†’ì€ ì ìˆ˜
- ë¶€ì •ì  í–‰ë™: ë‚®ì€ ì ìˆ˜
- ì¤‘ë¦½ì  ë‰´ìŠ¤: 50ì 

ì¶œë ¥ í˜•ì‹ (JSON):
{
  "scores": {
    "Expertise": [ì ìˆ˜1, ì ìˆ˜2, ..., ì ìˆ˜N],
    "Leadership": [ì ìˆ˜1, ì ìˆ˜2, ..., ì ìˆ˜N],
    ... (10ê°œ ì¹´í…Œê³ ë¦¬)
  }
}
"""

    def _load_news(self, politician_name: str) -> List[str]:
        """ì •ì¹˜ì¸ë³„ 150ê°œ ë‰´ìŠ¤ ë¡œë“œ"""
        news_file = f"news_data/{politician_name}_news.json"

        if os.path.exists(news_file):
            with open(news_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('news', [])[:150]  # ìµœëŒ€ 150ê°œ
        else:
            print(f"âš ï¸ {politician_name}: ë‰´ìŠ¤ íŒŒì¼ ì—†ìŒ")
            return []

    def _chunk_news(self, news_list: List[str], chunk_size: int = 30) -> List[List[str]]:
        """ë‰´ìŠ¤ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        return [news_list[i:i+chunk_size] for i in range(0, len(news_list), chunk_size)]

    async def evaluate_chunk_with_claude_cached(
        self,
        politician_name: str,
        news_chunk: List[str],
        chunk_num: int
    ) -> Dict:
        """Claudeë¡œ ì²­í¬ í‰ê°€ (í”„ë¡¬í”„íŠ¸ ìºì‹± í™œìš©)"""

        print(f"    ğŸ“Š Claude ì²­í¬ {chunk_num} í‰ê°€: {len(news_chunk)}ê°œ ë‰´ìŠ¤")

        # ë‰´ìŠ¤ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        news_json = json.dumps(
            [{"index": i+1, "content": news} for i, news in enumerate(news_chunk)],
            ensure_ascii=False
        )

        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=8000,
                system=[
                    {
                        "type": "text",
                        "text": self.evaluation_criteria,
                        "cache_control": {"type": "ephemeral"}  # ìºì‹±!
                    }
                ],
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": f"ì •ì¹˜ì¸: {politician_name}\n\në‰´ìŠ¤ ëª©ë¡:\n{news_json}",
                                "cache_control": {"type": "ephemeral"}  # ë‰´ìŠ¤ë„ ìºì‹±!
                            },
                            {
                                "type": "text",
                                "text": "ìœ„ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ 10ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."
                            }
                        ]
                    }
                ]
            )

            result = json.loads(response.content[0].text)

            # í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥
            usage = response.usage
            print(f"      í† í°: ì…ë ¥ {usage.input_tokens}, ì¶œë ¥ {usage.output_tokens}")
            if hasattr(usage, 'cache_read_input_tokens'):
                print(f"      ìºì‹œ: {usage.cache_read_input_tokens} í† í° ì¬ì‚¬ìš©!")

            return result

        except Exception as e:
            print(f"    âŒ Claude ì²­í¬ {chunk_num} ì˜¤ë¥˜: {str(e)}")
            return None

    async def evaluate_chunk_with_chatgpt(
        self,
        politician_name: str,
        news_chunk: List[str],
        chunk_num: int
    ) -> Dict:
        """ChatGPTë¡œ ì²­í¬ í‰ê°€"""

        print(f"    ğŸ“Š ChatGPT ì²­í¬ {chunk_num} í‰ê°€: {len(news_chunk)}ê°œ ë‰´ìŠ¤")

        news_json = json.dumps(
            [{"index": i+1, "content": news} for i, news in enumerate(news_chunk)],
            ensure_ascii=False
        )

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": self.evaluation_criteria},
                    {"role": "user", "content": f"""
ì •ì¹˜ì¸: {politician_name}

ë‰´ìŠ¤ ëª©ë¡:
{news_json}

ìœ„ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ 10ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
                    """}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )

            result = json.loads(response.choices[0].message.content)

            # í† í° ì‚¬ìš©ëŸ‰
            usage = response.usage
            print(f"      í† í°: ì…ë ¥ {usage.prompt_tokens}, ì¶œë ¥ {usage.completion_tokens}")

            return result

        except Exception as e:
            print(f"    âŒ ChatGPT ì²­í¬ {chunk_num} ì˜¤ë¥˜: {str(e)}")
            return None

    async def evaluate_chunk_with_grok(
        self,
        politician_name: str,
        news_chunk: List[str],
        chunk_num: int
    ) -> Dict:
        """Grokìœ¼ë¡œ ì²­í¬ í‰ê°€"""

        print(f"    ğŸ“Š Grok ì²­í¬ {chunk_num} í‰ê°€: {len(news_chunk)}ê°œ ë‰´ìŠ¤")

        news_json = json.dumps(
            [{"index": i+1, "content": news} for i, news in enumerate(news_chunk)],
            ensure_ascii=False
        )

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.x.ai/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.grok_api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "grok-beta",
                        "messages": [
                            {"role": "system", "content": self.evaluation_criteria},
                            {"role": "user", "content": f"""
ì •ì¹˜ì¸: {politician_name}

ë‰´ìŠ¤ ëª©ë¡:
{news_json}

ìœ„ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ 10ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
                            """}
                        ],
                        "temperature": 0.3
                    }
                ) as response:
                    data = await response.json()
                    result = json.loads(data['choices'][0]['message']['content'])

                    # í† í° ì‚¬ìš©ëŸ‰
                    usage = data.get('usage', {})
                    print(f"      í† í°: ì…ë ¥ {usage.get('prompt_tokens')}, ì¶œë ¥ {usage.get('completion_tokens')}")

                    return result

        except Exception as e:
            print(f"    âŒ Grok ì²­í¬ {chunk_num} ì˜¤ë¥˜: {str(e)}")
            return None

    async def evaluate_one_politician_chunked(self, politician_name: str) -> Dict:
        """í•œ ëª…ì˜ ì •ì¹˜ì¸ì„ ì²­í¬ ë°©ì‹ìœ¼ë¡œ í‰ê°€"""

        print(f"\nğŸ¯ í‰ê°€ ì‹œì‘: {politician_name}")

        # ë‰´ìŠ¤ ë¡œë“œ
        news_list = self._load_news(politician_name)

        if not news_list:
            print(f"âŒ {politician_name}: ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ")
            return None

        print(f"  ğŸ“° ë‰´ìŠ¤ ê°œìˆ˜: {len(news_list)}ê°œ")

        # ì²­í¬ë¡œ ë¶„í•  (30ê°œì”©)
        news_chunks = self._chunk_news(news_list, chunk_size=30)
        print(f"  ğŸ“¦ ì²­í¬ ê°œìˆ˜: {len(news_chunks)}ê°œ (ê° 30ê°œ)")

        # ê° ì²­í¬ë¥¼ 3ê°œ AIë¡œ í‰ê°€
        all_scores = {
            'chatgpt': {cat: [] for cat in CATEGORIES},
            'grok': {cat: [] for cat in CATEGORIES},
            'claude': {cat: [] for cat in CATEGORIES}
        }

        for i, chunk in enumerate(news_chunks, 1):
            print(f"\n  ğŸ“¦ ì²­í¬ {i}/{len(news_chunks)} í‰ê°€ ì¤‘...")

            # 3ê°œ AI ë™ì‹œ í‰ê°€
            chatgpt_task = self.evaluate_chunk_with_chatgpt(politician_name, chunk, i)
            grok_task = self.evaluate_chunk_with_grok(politician_name, chunk, i)
            claude_task = self.evaluate_chunk_with_claude_cached(politician_name, chunk, i)

            chatgpt_result, grok_result, claude_result = await asyncio.gather(
                chatgpt_task, grok_task, claude_task
            )

            # ì ìˆ˜ ëˆ„ì 
            if chatgpt_result:
                for cat in CATEGORIES:
                    all_scores['chatgpt'][cat].extend(chatgpt_result['scores'][cat])

            if grok_result:
                for cat in CATEGORIES:
                    all_scores['grok'][cat].extend(grok_result['scores'][cat])

            if claude_result:
                for cat in CATEGORIES:
                    all_scores['claude'][cat].extend(claude_result['scores'][cat])

        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        pooling_scores = self._calculate_pooling_scores(all_scores)

        print(f"âœ… ì™„ë£Œ: {politician_name}")

        return {
            'politician': politician_name,
            'scores': all_scores,
            'pooling': pooling_scores
        }

    def _calculate_pooling_scores(self, all_scores: Dict) -> Dict:
        """Pooling ì ìˆ˜ ê³„ì‚° (3ê°œ AI í‰ê· )"""

        pooling = {}

        for category in CATEGORIES:
            chatgpt_scores = all_scores['chatgpt'][category]
            grok_scores = all_scores['grok'][category]
            claude_scores = all_scores['claude'][category]

            if chatgpt_scores and grok_scores and claude_scores:
                chatgpt_avg = sum(chatgpt_scores) / len(chatgpt_scores)
                grok_avg = sum(grok_scores) / len(grok_scores)
                claude_avg = sum(claude_scores) / len(claude_scores)

                pooling[category] = (chatgpt_avg + grok_avg + claude_avg) / 3
            else:
                pooling[category] = 0

        return pooling

    async def evaluate_batch(self, politicians: List[str]) -> List[Dict]:
        """ë°°ì¹˜ í‰ê°€ (ë³‘ë ¬)"""

        print(f"\n{'='*60}")
        print(f"ğŸ“¦ ë°°ì¹˜ í‰ê°€ ì‹œì‘: {len(politicians)}ëª…")
        print(f"{'='*60}")

        tasks = [self.evaluate_one_politician_chunked(p) for p in politicians]
        results = await asyncio.gather(*tasks)

        return [r for r in results if r is not None]

    async def evaluate_all_27(self) -> List[Dict]:
        """27ëª… ì „ì²´ í‰ê°€"""

        print("\n" + "="*60)
        print("ğŸš€ ì´ˆê³ ì† + ì´ˆì €ë¹„ìš© V24.5 Pooling í‰ê°€ ì‹œì‘")
        print("="*60)
        print(f"ëŒ€ìƒ: 27ëª… ì •ì¹˜ì¸")
        print(f"ë°©ì‹: ì²­í¬ + ìºì‹± + ë³‘ë ¬ ì²˜ë¦¬")
        print(f"ì˜ˆìƒ ì‹œê°„: 1-2ì‹œê°„")
        print(f"ì˜ˆìƒ í† í° ì ˆê°: 90%")
        print("="*60 + "\n")

        # 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• 
        groups = [
            REMAINING_POLITICIANS[0:9],
            REMAINING_POLITICIANS[9:18],
            REMAINING_POLITICIANS[18:27]
        ]

        all_results = []
        start_time = datetime.now()

        for i, group in enumerate(groups, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“¦ ê·¸ë£¹ {i}/3 ì‹œì‘ ({len(group)}ëª…)")
            print(f"{'='*60}")

            group_start = datetime.now()
            group_results = await self.evaluate_batch(group)
            group_elapsed = (datetime.now() - group_start).total_seconds() / 60

            all_results.extend(group_results)

            # ì¦‰ì‹œ ì €ì¥
            self._save_results(group_results, group_num=i)

            print(f"\nâœ… ê·¸ë£¹ {i} ì™„ë£Œ!")
            print(f"  ì†Œìš” ì‹œê°„: {group_elapsed:.1f}ë¶„")
            print(f"  ì „ì²´ ì§„í–‰ë¥ : {len(all_results)}/27ëª…")

        total_elapsed = (datetime.now() - start_time).total_seconds() / 60

        print(f"\n{'='*60}")
        print(f"ğŸ‰ ì „ì²´ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"í‰ê°€ ì™„ë£Œ: {len(all_results)}/27ëª…")
        print(f"ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ë¶„ ({total_elapsed/60:.2f}ì‹œê°„)")
        print(f"{'='*60}\n")

        return all_results

    def _save_results(self, results: List[Dict], group_num: int):
        """ê²°ê³¼ ì €ì¥"""

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"pooling_cached_group{group_num}_{timestamp}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"  ğŸ’¾ ì €ì¥: {filename}")


async def main():
    """ë©”ì¸ ì‹¤í–‰"""

    evaluator = CachedPoolingEvaluator()
    results = await evaluator.evaluate_all_27()

    # ìµœì¢… ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"pooling_cached_all_27_{timestamp}.json"

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"âœ… ìµœì¢… ì €ì¥: {filename}")

    # í†µê³„
    print("\nğŸ“Š í‰ê°€ í†µê³„:")
    for result in results:
        politician = result['politician']
        pooling = result['pooling']
        avg_score = sum(pooling.values()) / len(pooling)
        print(f"  {politician}: {avg_score:.2f}ì ")


if __name__ == "__main__":
    asyncio.run(main())
