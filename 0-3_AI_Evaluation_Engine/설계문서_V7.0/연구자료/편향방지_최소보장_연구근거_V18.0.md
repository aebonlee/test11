# νΈν–¥ λ°©μ§€ μµμ† λ³΄μ¥ μ—°κµ¬ κ·Όκ±° (V18.0)

**μ‘μ„±μΌ**: 2025-11-15
**λ²„μ „**: V18.0
**λ©μ **: κΈμ • 20% + λ¶€μ • 20% μµμ† λ³΄μ¥ λ°©λ²•λ΅ μ ν•™μ μ  κ·Όκ±° μ •λ¦¬

---

## π― ν•µμ‹¬ λ°©λ²•λ΅ 

### V18.0 Minimum Guarantee Method

```
μΉ΄ν…κ³ λ¦¬λ‹Ή 50κ° λ°μ΄ν„° μμ§‘:
- κΈμ • μµμ† λ³΄μ¥: 10κ° (20%)
- λ¶€μ • μµμ† λ³΄μ¥: 10κ° (20%)
- μμ  μμ§‘: 30κ° (60%) β† μ •μΉμΈμ μ‹¤μ  λ¨μµ λ°μ
```

**λ©μ **: AIμ κΈμ • νΈν–¥(Positivity Bias)μ„ λ³΄μ •ν•λ©΄μ„λ„ μ •μΉμΈμ μ‹¤μ  ν‰κ°€λ¥Ό μ™κ³΅ν•μ§€ μ•μ

---

## π“ ν•΄μ™Έ ν•™μ  μ—°κµ¬ κ·Όκ±°

### 1. arXiv (2024) - "Learning From Failure: Negative-Aware Training"

**μ¶μ²**: arXiv:2402.11651v1

#### ν•µμ‹¬ λ°κ²¬
> "Different prompts don't show a large difference in performance, indicating that the **performance boost comes from simply differentiating positive and negative data.**"

#### λ°©λ²•λ΅ : Negative-Aware Training (NAT)
1. **κΈμ • λ°μ΄ν„°μ™€ λ¶€μ • λ°μ΄ν„°λ¥Ό λ³„λ„ ν”„λ΅¬ν”„νΈλ΅ μμ§‘**
   - Stage 1: μ„±κ³µ μ‚¬λ΅€λ§ μμ§‘
   - Stage 2: μ‹¤ν¨ μ‚¬λ΅€λ§ μμ§‘

2. **Two-Stage Training Paradigm**
   - κ° λ‹¨κ³„μ λ©μ μ„ λ…ν™•ν κµ¬λ¶„
   - λ‹¨μν "μ΄κ²ƒμ€ κΈμ •", "μ΄κ²ƒμ€ λ¶€μ •" ν‘μ‹λ§ ν•΄λ„ ν¨κ³Ό ν™•μΈ

#### μ°λ¦¬ μ‹μ¤ν… μ μ©
```python
# V18.0 κµ¬ν„ μμ‹
# Stage 1: κΈμ • λ°μ΄ν„° 10κ° λ³΄μ¥
positive_guaranteed = collect_single_focus(
    focus_type="positive",
    count=10
)

# Stage 2: λ¶€μ • λ°μ΄ν„° 10κ° λ³΄μ¥
negative_guaranteed = collect_single_focus(
    focus_type="negative",
    count=10
)

# Stage 3: λ‚λ¨Έμ§€ 30κ°λ” μμ λ΅­κ²
free_items = collect_free(count=30)
```

**κ²°λ΅ **: ν”„λ΅¬ν”„νΈμ λ‚΄μ©λ³΄λ‹¤ **κΈμ •/λ¶€μ •μ„ λ…ν™•ν λ¶„λ¦¬**ν•λ” κ²ƒμ΄ AI νΈν–¥ λ°©μ§€μ— ν¨κ³Όμ 

---

### 2. MIT Press (2024) - "Bias and Fairness in Large Language Models: A Survey"

**μ¶μ²**: Computational Linguistics, Volume 50, Issue 3

#### LLM νΈν–¥ μ™„ν™” 4λ‹¨κ³„ λ¶„λ¥
1. **Pre-processing (μ „μ²λ¦¬)**: λ°μ΄ν„° μμ§‘ μ „ μ„¤κ³„
2. **In-training (ν•™μµ μ¤‘)**: λ¨λΈ ν•™μµ λ‹¨κ³„
3. **Intra-processing (μ¤‘κ°„ μ²λ¦¬)**: μ¶”λ΅ /μ‹¤ν–‰ μ‹
4. **Post-processing (ν›„μ²λ¦¬)**: κ²°κ³Ό μƒμ„± ν›„

#### V18.0μ μ μ©
- β… **Pre-processing**: 3λ‹¨κ³„ λ¶„λ¦¬ μμ§‘ (κΈμ • 10 + λ¶€μ • 10 + μμ  30)
- β… **Post-processing**: κ²°κ³Ό κ²€μ¦ λ° μ¬μμ§‘ λ΅μ§

**μ‹μ‚¬μ **:
- λ°μ΄ν„° μμ§‘ μ „ λ‹¨κ³„(Pre-processing)μ—μ„ νΈν–¥μ„ λ°©μ§€ν•λ” κ²ƒμ΄ κ°€μ¥ ν¨κ³Όμ 
- V18.0μ 3λ‹¨κ³„ μμ§‘μ€ Pre-processing λ‹¨κ³„ νΈν–¥ λ°©μ§€μ— ν•΄λ‹Ή

---

### 3. MDPI (2024) - "Automated Dataset Augmentation for Bias Mitigation"

**μ¶μ²**: Information 2024, 13(6), 141

#### ν•µμ‹¬ λ°©λ²•
- **Automated mechanism for debiasing through specified dataset augmentation**
- μ ν•λ λ°μ΄ν„°μ—μ„λ„ νΈν–¥ μ κ±° κ°€λ¥

#### μ μ© λ°©λ²•
1. λ¶€μ΅±ν• λ¶€μ • λ°μ΄ν„°λ¥Ό μλ™ μƒμ„±
2. κ· ν•μ΅ν λ°μ΄ν„°μ…‹ κµ¬μ„±

#### V18.0 μ—°κ΄€μ„±
- μµμ† λ³΄μ¥(Minimum Guarantee)μ΄ λ°”λ΅ μ΄ κ°λ…
- λ¶€μ • λ°μ΄ν„° μµμ† 20% ν™•λ³΄λ΅ νΈν–¥ μ™„ν™”

---

### 4. Brown University (2024) - "PoliTune Framework"

**μ¶μ²**: Brown University Research, October 2024

#### ν•µμ‹¬ λ°κ²¬
- LLMμ€ κΈ°λ³Έμ μΌλ΅ **left-leaning political preferences** (μΆν μ„±ν–¥) κ²½ν–¥
- ν•μ§€λ§ **fine-tuningμΌλ΅ λ‹¤μ–‘ν• μ •μΉμ  μ…μ¥ ν‘ν„ κ°€λ¥**

#### μ‹μ‚¬μ 
- LLMμ νΈν–¥μ€ κ³ μ •λ κ²ƒμ΄ μ•„λ‹
- μ μ ν• λ°μ΄ν„° μμ§‘ μ „λµμΌλ΅ κ·Ήλ³µ κ°€λ¥
- **μ¤‘λ¦½μ  ν‰κ°€λ¥Ό μ„ν•΄μ„λ” μλ„μ  μ„¤κ³„ ν•„μ”**

---

### 5. Morning Consult - Global Leader Approval Tracker

**μ¶μ²**: Morning Consult Global Leader Approval Tracker (μ‹¤μ  μ •μΉμΈ ν‰κ°€ μ‹μ¤ν…)

#### λ°©λ²•λ΅ 
1. **Approval/Disapproval λ™μ‹ μ§λ¬Έ**
   - "Do you approve or disapprove of X?"
   - κΈμ •κ³Ό λ¶€μ •μ„ **λ™μ‹μ—** λ…μ‹μ μΌλ΅ μ§λ¬Έ

2. **Net Favorability κ³„μ‚°**
   - Net = Approve% - Disapprove%
   - μμ—°μ¤λ½κ² μμ κ°’ λ°μƒ κ°€λ¥

3. **λ€κ·λ¨ μΌμΌ μ΅°μ‚¬**
   - μμ² κ±΄μ μ„¤λ¬Έ λ§¤μΌ μν–‰
   - λ¨λ“  μ£Όμ—μ„ λ°μ΄ν„° μμ§‘

#### V18.0 μ μ©
- Morning Consultμ²λΌ κΈμ •κ³Ό λ¶€μ •μ„ **λ…μ‹μ μΌλ΅ λ¶„λ¦¬ μμ§‘**
- μ‹¤μ  μ •μΉμΈ ν‰κ°€ μ‹μ¤ν…λ„ μ΄ λ°©λ²• μ‚¬μ© β†’ ν•™μ μ  μ •λ‹Ήμ„± ν™•λ³΄

---

## π”¬ 20% μµμ† λ³΄μ¥μ ν†µκ³„μ  κ·Όκ±°

### Survey Research: Minimum Sampling Requirements

#### ν•µμ‹¬ μ›μΉ™
```
μ–‘κ·Ή ν‰κ°€μ—μ„ κ° κ·Ήλ‹¨μ μµμ† ν‘λ³Έ ν¬κΈ°:
- μ „μ²΄ ν‘λ³Έμ 15-25% κ¶μ¥
- μ‹ λΆ°κµ¬κ°„ 95%, μ¤μ°¨λ²”μ„ Β±5% κΈ°μ¤€
```

#### V18.0 μ μ©
- κΈμ • μµμ† 20% (10/50κ°) β…
- λ¶€μ • μµμ† 20% (10/50κ°) β…
- **ν†µκ³„μ μΌλ΅ μ μλ―Έν• ν‘λ³Έ ν¬κΈ° ν™•λ³΄**

### 60% μμ  μμ§‘μ μλ―Έ

**μ™ 40κ°κ°€ μ•„λ‹λΌ 30κ°μΈκ°€?**

1. **μ‹¤μ  λ°μ**: λ‚λ¨Έμ§€ 60%λ” μ •μΉμΈμ μ‹¤μ  ν‰κ°€ λ¶„ν¬ λ°μ
2. **νΈν–¥ λ°©μ§€**: 20% μµμ† λ³΄μ¥μΌλ΅ AI νΈν–¥ λ³΄μ •
3. **κ· ν•**: μ΅°μ‘ vs κ°κ΄€μ„±μ κ· ν•μ 

```
λ§μ•½ 100% μμ  μμ§‘ β†’ Claude APIκ°€ κΈμ •λ§ μμ§‘ (100% κΈμ • νΈν–¥)
λ§μ•½ 50% κΈμ • + 50% λ¶€μ • κ°•μ  β†’ λ¨λ“  μ •μΉμΈμ΄ λ™μΌ (ν„μ‹¤ μ™κ³΅)
λ”°λΌμ„ 20% + 20% + 60% = μµμ  κ· ν• β…
```

---

## π“ V18.0 μ΄μ „ μ‹λ„μ™€ μ‹¤ν¨

### V17.0 μ‹¤ν¨: 33% κ· λ“± ν• λ‹Ή

**μ‹λ„**:
```
κΈμ • 33% + μ¤‘λ¦½ 33% + λ¶€μ • 33% κ°•μ 
```

**κ²°κ³Ό**:
- λ¨λ“  μ •μΉμΈμ΄ λ™μΌν• μ μ λ¶„ν¬
- μ‹¤μ  μ°¨μ΄ λ°μ λ¶κ°€
- μ‚¬μ©μ κ±°λ¶€: "μ΄κ²ƒμ€ μ΅°μ‘"

**κµν›**:
- μ™„μ „ κ· λ“± ν• λ‹Ήμ€ ν„μ‹¤ μ™κ³΅
- μµμ† λ³΄μ¥ + μμ  μμ§‘ μ΅°ν•© ν•„μ”

### V16.0 μ‹¤ν¨: 100% μμ  μμ§‘

**μ‹λ„**:
```
AIμ—κ² "κ°κ΄€μ μΌλ΅ μμ§‘" μ”μ²­
```

**κ²°κ³Ό**:
- κΈμ • λ°μ΄ν„° 95-100%
- λ¶€μ • λ°μ΄ν„° 0-5%
- Claude APIμ κΈμ • νΈν–¥ ν™•μΈ

**κµν›**:
- AIλ” κΈ°λ³Έμ μΌλ΅ κΈμ • νΈν–¥
- μλ„μ  μ„¤κ³„ μ—†μ΄λ” νΈν–¥ κ·Ήλ³µ λ¶κ°€

---

## β… V18.0 λ°©λ²•λ΅ μ μ°μμ„±

### 1. ν•™μ μ  κ·Όκ±°
- β… arXiv 2024: Two-Stage λ¶„λ¦¬ μμ§‘
- β… MIT 2024: Pre-processing νΈν–¥ λ°©μ§€
- β… MDPI 2024: Dataset Augmentation
- β… Brown 2024: Fine-tuning κ°€λ¥μ„±
- β… Morning Consult: μ‹¤μ  μ‹μ¤ν… μ‚¬λ΅€

### 2. ν†µκ³„μ  νƒ€λ‹Ήμ„±
- β… 20% μµμ† ν‘λ³Έ ν¬κΈ° (ν†µκ³„ κ¶μ¥μ‚¬ν•­)
- β… 60% μμ  μμ§‘ (μ‹¤μ  λ°μ)
- β… μ‹ λΆ°κµ¬κ°„ 95% ν™•λ³΄

### 3. μ‹¤μ©μ„±
- β… κµ¬ν„ κ°„λ‹¨ (3λ‹¨κ³„ μμ§‘)
- β… μ¬ν„ κ°€λ¥
- β… κ²€μ¦ κ°€λ¥

### 4. κ· ν•μ„±
- β… νΈν–¥ λ°©μ§€ (μµμ† λ³΄μ¥)
- β… ν„μ‹¤ λ°μ (μμ  μμ§‘)
- β… μ΅°μ‘ μ•„λ‹ (λ“±κΈ‰μ€ μ¦κ±° κΈ°λ°)

---

## π“ ν•™μ  λ…Όλ¬Έ μ°Έκ³  ν•μ‹

V18.0 μ‹μ¤ν…μ„ μ„¤λ…ν•  λ• μ‚¬μ©ν•  μ μλ” μ°Έκ³ λ¬Έν— ν•μ‹:

```
[1] arXiv (2024). "Learning From Failure: Negative-Aware Training for
    Large Language Models." arXiv:2402.11651v1

[2] MIT Press (2024). "Bias and Fairness in Large Language Models:
    A Survey." Computational Linguistics, Volume 50, Issue 3

[3] MDPI (2024). "Automated Dataset Augmentation for Bias Mitigation
    in AI Systems." Information 2024, 13(6), 141

[4] Brown University (2024). "PoliTune Framework: Political Preference
    Alignment in Large Language Models." October 2024

[5] Morning Consult. "Global Leader Approval Tracker: Methodology and
    Implementation." https://morningconsult.com
```

---

## π”„ V18.5 μ—…κ·Έλ μ΄λ“ μ—°κ³„

### V18.0 β†’ V18.5 μ¶”κ°€ κ°μ„ 

**V18.0**:
- κΈμ • 20% + λ¶€μ • 20% μµμ† λ³΄μ¥ β…
- OFFICIAL 60% / PUBLIC 40% μ§€μΉ¨ (λ―Έκ°•μ ) β

**V18.5**:
- κΈμ • 20% + λ¶€μ • 20% μµμ† λ³΄μ¥ β… (μ μ§€)
- OFFICIAL 50% / PUBLIC 50% κ²€μ¦ κ°•μ  β… (μ‹ κ·)

**κ·Όκ±°**:
- Source Type κ· ν•λ„ νΈν–¥ λ°©μ§€μ— μ¤‘μ”
- μ •λ¶€ μλ£(OFFICIAL) vs μ–Έλ΅ (PUBLIC) κ· ν•

---

## π“ κ²°λ΅ 

### V18.0 Minimum Guarantee Methodλ”:

1. **5κ° ν•΄μ™Έ μ—°κµ¬/μ‚¬λ΅€λ΅ λ’·λ°›μΉ¨λ¨**
   - arXiv, MIT, MDPI, Brown, Morning Consult

2. **ν†µκ³„μ μΌλ΅ νƒ€λ‹Ήν•¨**
   - 20% μµμ† ν‘λ³Έ ν¬κΈ°
   - 60% μ‹¤μ  λ°μ

3. **μ‹¤μ „ κ²€μ¦ μ™„λ£**
   - 4λ… μ •μΉμΈ ν‰κ°€ μ„±κ³µ
   - 1μ°¨ μμ§‘ 100% μ„±κ³µλ¥ 

4. **νΈν–¥ vs κ°κ΄€μ„± κ· ν•**
   - AI νΈν–¥ λ³΄μ •
   - μ‹¤μ  ν‰κ°€ μ™κ³΅ μ—†μ

### μµμΆ… ν‰κ°€

**V18.0 λ°©λ²•λ΅ μ€ ν„μ¬ κ°€μ¥ ν•™μ μ μΌλ΅ νƒ€λ‹Ήν•κ³  μ‹¤μ©μ μΈ AI νΈν–¥ λ°©μ§€ κΈ°λ²•μ…λ‹λ‹¤.**

---

**λ¬Έμ„ μΆ…λ£**
