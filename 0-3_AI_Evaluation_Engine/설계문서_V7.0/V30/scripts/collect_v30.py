# -*- coding: utf-8 -*-
"""
V30 2ê°œ AI ë¶„ë‹´ ì›¹ê²€ìƒ‰ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (ë¹„ìš© ìµœì í™” ë²„ì „)

í•µì‹¬ ë³€ê²½ (V30):
1. 2ê°œ AI ë¶„ë‹´ ìˆ˜ì§‘ (90-10) - ë¹„ìš© ìµœì í™”
   - Gemini 90%: ê³µì‹ 50ê°œ + ê³µê°œ 40ê°œ (Google Search ë¬´ë£Œ)
   - Grok 10%: ê³µê°œ 10ê°œ (X/íŠ¸ìœ„í„° ì „ë‹´)

   âš ï¸ Perplexity = ì œê±° (401 ì—ëŸ¬ + ë¹„ìš© í­íƒ„ $1,050+/100ëª…)
   âš ï¸ Claude/ChatGPT = ìˆ˜ì§‘ ì œì™¸ (ì›¹ê²€ìƒ‰ ë¹„ìš© ë¬¸ì œ)
   - Claude web_search: ê²€ìƒ‰ë‹¹ $0.01 ì¶”ê°€ ê³¼ê¸ˆ
   - ChatGPT Bing: ë³„ë„ ê³¼ê¸ˆ

2. ì›¹ê²€ìƒ‰ í•„ìˆ˜ (ìˆ˜ì§‘ AIë§Œ)
   - Gemini: google_search grounding (ë¬´ë£Œ) - ë‰´ìŠ¤, SNS, ìœ„í‚¤, ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹° ì „ì²´
   - Grok: X/Twitter ì‹¤ì‹œê°„ ì ‘ê·¼

   âš ï¸ Claude/ChatGPTëŠ” ìˆ˜ì§‘ ì œì™¸ (í‰ê°€ì—ë§Œ ì‚¬ìš©)

3. ì¹´í…Œê³ ë¦¬ë‹¹ 100ê°œ ìˆ˜ì§‘ (ì´ 1,000ê°œ/ì •ì¹˜ì¸)

4. 20-20-60 ê· í˜•
   - ë¶€ì • 20ê°œ + ê¸ì • 20ê°œ + ììœ  60ê°œ

ì‚¬ìš©ë²•:
    # ì „ì²´ ìˆ˜ì§‘ (Gemini + Grok)
    python collect_v30.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ"

    # íŠ¹ì • AIë§Œ ì‹¤í–‰
    python collect_v30.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ" --ai=Gemini

    # íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ
    python collect_v30.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ" --category=1

    # ë³‘ë ¬ ì‹¤í–‰ (ë¹ ë¦„, ê¶Œì¥)
    python collect_v30.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ" --parallel

    # ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ (ì¹´í…Œê³ ë¦¬ë‹¹ 10ê°œ)
    python collect_v30.py --politician_id=62e7b453 --politician_name="ì˜¤ì„¸í›ˆ" --parallel --test
"""

import os
import sys
import json
import re
import argparse
import time
import random
import requests
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from supabase import create_client
from dotenv import load_dotenv

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import io
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except AttributeError:
        # ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆê±°ë‚˜ bufferê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
        pass

# ============================================================
# topic_mode â†’ DB sentiment ë§¤í•‘
# ============================================================
def topic_mode_to_sentiment(topic_mode):
    """topic_modeë¥¼ DB sentiment ê°’ìœ¼ë¡œ ë³€í™˜

    Args:
        topic_mode: 'negative', 'positive', 'free'

    Returns:
        sentiment: 'negative', 'positive', 'free'

    Notes:
        - DB sentiment CHECK ì œì•½: ('positive', 'negative', 'neutral', 'free')
        - topic_mode 'free'ëŠ” DBì—ì„œ ê·¸ëŒ€ë¡œ 'free'ë¡œ ì €ì¥
        - 'free' = ììœ ë¡­ê²Œ ìˆ˜ì§‘ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ëª¨ë‘ í¬í•¨)
    """
    mapping = {
        'negative': 'negative',
        'positive': 'positive',
        'free': 'free'  # âœ… ìˆ˜ì •: 'free' ê·¸ëŒ€ë¡œ ì €ì¥
    }
    return mapping.get(topic_mode, 'free')


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

# V30 í…Œì´ë¸”ëª…
TABLE_COLLECTED_DATA = "collected_data_v30"

# AI í´ë¼ì´ì–¸íŠ¸ ìºì‹œ
ai_clients = {}

# ì¹´í…Œê³ ë¦¬ ì •ì˜ (V30 - V28.3 ê¸°ì¤€)
CATEGORIES = [
    ("expertise", "ì „ë¬¸ì„±"),
    ("leadership", "ë¦¬ë”ì‹­"),
    ("vision", "ë¹„ì „"),
    ("integrity", "ì²­ë ´ì„±"),
    ("ethics", "ìœ¤ë¦¬ì„±"),
    ("accountability", "ì±…ì„ê°"),
    ("transparency", "íˆ¬ëª…ì„±"),
    ("communication", "ì†Œí†µëŠ¥ë ¥"),
    ("responsiveness", "ëŒ€ì‘ì„±"),
    ("publicinterest", "ê³µìµì„±")
]

# V30 ìˆ˜ì§‘ ë¹„ìœ¨ (ì¹´í…Œê³ ë¦¬ë‹¹ 100ê°œ) - ë¹„ìš© ìµœì í™” ë²„ì „
# âš ï¸ Claude/ChatGPT = ìˆ˜ì§‘ ì œì™¸ (ì›¹ê²€ìƒ‰ ë¹„ìš© ë¬¸ì œ)
# - Claude web_search: ê²€ìƒ‰ë‹¹ $0.01 ì¶”ê°€ ê³¼ê¸ˆ
# - ChatGPT Bing: ë³„ë„ ê³¼ê¸ˆ
# â†’ ìˆ˜ì§‘: Gemini 60% + Perplexity 30% + Grok 10%
# â†’ í‰ê°€ë§Œ: Claude, ChatGPT
#
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”´ AIë³„ ë‹´ë‹¹ ì†ŒìŠ¤ (V30 ì—­í•  ë¶„ë¦¬)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# | AI         | OFFICIAL | PUBLIC                    | ê¸ˆì§€ ì†ŒìŠ¤              |
# |------------|----------|---------------------------|------------------------|
# | Gemini     | 50ê°œ     | 40ê°œ(ì „ì²´ ë‹´ë‹¹)           | âŒ (ì—†ìŒ)              |
# | Grok       | 0ê°œ      | 10ê°œ(X/íŠ¸ìœ„í„°ë§Œ)          | âŒ ë‰´ìŠ¤, âŒ ê¸°íƒ€        |
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Gemini PUBLIC ë‹´ë‹¹ (ì „ì²´):
#   - ë‰´ìŠ¤/ì–¸ë¡ : ì¡°ì„ , ì¤‘ì•™, ë™ì•„, í•œê²¨ë ˆ, ê²½í–¥, KBS, MBC, SBS, ë¡œì´í„°, AP, AFP, BBC, CNN ë“±
#   - SNS: YouTube, Instagram, Facebook
#   - ìœ„í‚¤í”¼ë””ì•„ (í•œê¸€/ì˜ë¬¸)
#   - ë¸”ë¡œê·¸/ì¹¼ëŸ¼: ë„¤ì´ë²„ ë¸”ë¡œê·¸, ë¸ŒëŸ°ì¹˜, ì „ë¬¸ê°€ ì¹¼ëŸ¼
#   - ì»¤ë®¤ë‹ˆí‹°: ë‚˜ë¬´ìœ„í‚¤, ì¹´í˜
# Grok PUBLIC ë‹´ë‹¹ (X/íŠ¸ìœ„í„° ì „ë‹´):
#   - X(Twitter) ì‹¤ì‹œê°„ ê²Œì‹œê¸€, ëŒ“ê¸€, íŠ¸ë Œë“œ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
COLLECT_DISTRIBUTION = {
    "Gemini": {
        "official": 50,  # OFFICIAL 100% (Google Search ë¬´ë£Œ)
        "public": 40,    # PUBLIC ì „ì²´ ë‹´ë‹¹: ë‰´ìŠ¤, SNS, ìœ„í‚¤, ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹° (Google Search ë¬´ë£Œ)
        "total": 90      # 90%
    },
    "Grok": {
        "official": 0,
        "public": 10,    # PUBLIC: X/íŠ¸ìœ„í„°ë§Œ!
        "total": 10      # 10%
    }
    # âš ï¸ Perplexity: ì œê±° (401 ì—ëŸ¬ + ë¹„ìš© í­íƒ„ $1,050+/100ëª…)
    # âš ï¸ Claude: ìˆ˜ì§‘ ì œì™¸ (í‰ê°€ë§Œ) - web_search ë¹„ìš© ë¬¸ì œ
    # âš ï¸ ChatGPT: ìˆ˜ì§‘ ì œì™¸ (í‰ê°€ë§Œ) - Bing ê²€ìƒ‰ ë¹„ìš© ë¬¸ì œ
}

# ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ìš© ë°°ë¶„ (ì¹´í…Œê³ ë¦¬ë‹¹ 10ê°œ) - ë¹ ë¥¸ ê²€ì¦ìš©
# 90-10 ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ 1/10 ê·œëª¨
TEST_DISTRIBUTION = {
    "Gemini": {
        "official": 5,   # OFFICIAL í…ŒìŠ¤íŠ¸
        "public": 4,     # PUBLIC í…ŒìŠ¤íŠ¸ (ì „ì²´ ë‹´ë‹¹)
        "total": 9       # 90%
    },
    "Grok": {
        "official": 0,
        "public": 1,     # PUBLIC í…ŒìŠ¤íŠ¸ (X/íŠ¸ìœ„í„°)
        "total": 1       # 10%
    }
}

# 20-20-60 ê· í˜• ë°°ë¶„ (ë¶€ì • 20% + ê¸ì • 20% + ììœ  60%)
# ê° AIë³„ë¡œ ë¶€ì •/ê¸ì •/ììœ  ê°œìˆ˜ ì„¤ì •
SENTIMENT_DISTRIBUTION = {
    "Gemini": {
        "official": {"negative": 10, "positive": 10, "free": 30},  # 50ê°œ
        "public": {"negative": 8, "positive": 8, "free": 24}       # 40ê°œ (ë‰´ìŠ¤ í¬í•¨ ì „ì²´)
    },
    "Grok": {
        "official": {"negative": 0, "positive": 0, "free": 0},     # 0ê°œ
        "public": {"negative": 2, "positive": 2, "free": 6}        # 10ê°œ
    }
}

# í…ŒìŠ¤íŠ¸ ëª¨ë“œìš© 20-20-60 ë°°ë¶„ (1/10 ê·œëª¨)
TEST_SENTIMENT_DISTRIBUTION = {
    "Gemini": {
        "official": {"negative": 1, "positive": 1, "free": 3},     # 5ê°œ
        "public": {"negative": 1, "positive": 1, "free": 2}        # 4ê°œ (ì „ì²´ ë‹´ë‹¹)
    },
    "Grok": {
        "official": {"negative": 0, "positive": 0, "free": 0},     # 0ê°œ
        "public": {"negative": 0, "positive": 0, "free": 1}        # 1ê°œ
    }
}

# AI ëª¨ë¸ ì„¤ì •
AI_CONFIGS = {
    "Claude": {
        "model": "claude-3-5-haiku-20241022",
        "env_key": "ANTHROPIC_API_KEY"
    },
    "ChatGPT": {
        "model": "gpt-4o-mini",
        "env_key": "OPENAI_API_KEY"
    },
    "Grok": {
        "model": "grok-2",
        "env_key": "XAI_API_KEY",
        "base_url": "https://api.x.ai/v1"
    },
    "Gemini": {
        "model": "gemini-2.0-flash",
        "env_key": "GEMINI_API_KEY"
    }
    # Perplexity: ì œê±° (401 ì—ëŸ¬ + ë¹„ìš© í­íƒ„)
}

# ê³µì‹ ë°ì´í„° ë„ë©”ì¸ (Gemini OFFICIAL ì†ŒìŠ¤)
OFFICIAL_DOMAINS = [
    "assembly.go.kr",
    "likms.assembly.go.kr",
    "mois.go.kr",
    "korea.kr",
    "nec.go.kr",
    "bai.go.kr",
    "pec.go.kr",
    "scourt.go.kr",
    "nesdc.go.kr",
    "manifesto.or.kr",
    "peoplepower21.org",
    "theminjoo.kr",
    "seoul.go.kr",
    "gg.go.kr",
    "busan.go.kr",
    "incheon.go.kr",
    "daegu.go.kr",
    "daejeon.go.kr",
    "gwangju.go.kr",
    "ulsan.go.kr",
    "sejong.go.kr",
    "open.go.kr",
    "acrc.go.kr",
    "humanrights.go.kr"
]

# ì •ì¹˜ì¸ ìƒì„¸ ì •ë³´ ìºì‹œ
_politician_info_cache = {}

def get_politician_info(politician_id):
    """ì •ì¹˜ì¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë™ëª…ì´ì¸ êµ¬ë¶„ìš©)"""
    if politician_id in _politician_info_cache:
        return _politician_info_cache[politician_id]

    try:
        result = supabase.table('politicians').select('*').eq('id', politician_id).execute()
        if result.data:
            p = result.data[0]
            birth_year = ""
            if p.get('birth_date'):
                birth_year = str(p.get('birth_date'))[:4] + "ë…„ìƒ"

            info = {
                'name': p.get('name', ''),
                'party': p.get('party', ''),
                'position': p.get('position', 'êµ­íšŒì˜ì›'),
                'district': p.get('district', ''),
                'birth_year': birth_year,
                'search_string': f"{p.get('party', '')} {p.get('name', '')} {p.get('position', 'êµ­íšŒì˜ì›')}" + (f" ({birth_year})" if birth_year else "")
            }
            _politician_info_cache[politician_id] = info
            return info
    except Exception as e:
        print(f"  âš ï¸ ì •ì¹˜ì¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    return {'name': '', 'party': '', 'position': 'êµ­íšŒì˜ì›', 'district': '', 'birth_year': '', 'search_string': ''}

# ì¹´í…Œê³ ë¦¬ë³„ 10ê°œ í•­ëª© (V28.3 ê¸°ì¤€ ì¤‘ë¦½í™”)
CATEGORY_ITEMS = {
    "expertise": [
        ("ìµœì¢… í•™ë ¥ ìˆ˜ì¤€", "í•™ë ¥ ë°•ì‚¬ ì„ì‚¬ í•™ì‚¬ í•™ìœ„"),
        ("ì§ë¬´ ê´€ë ¨ ìê²©ì¦", "ìê²©ì¦ ë³€í˜¸ì‚¬ CPA ê³µì¸"),
        ("ê´€ë ¨ ë¶„ì•¼ ê²½ë ¥ ì—°ìˆ˜", "ê²½ë ¥ ê·¼ë¬´ ì¬ì§ ì—°ìˆ˜"),
        ("ì§ë¬´ êµìœ¡ ì´ìˆ˜", "êµìœ¡ ì—°ìˆ˜ ì´ìˆ˜ ì°¸ì—¬"),
        ("ì „ë¬¸ ë¶„ì•¼ ê¸°ê³ /ì €ì„œ", "ì €ì„œ ê¸°ê³  ì¶œíŒ ì €ìˆ "),
        ("í•™ìˆ  ì—°êµ¬ ì‹¤ì ", "ë…¼ë¬¸ ì—°êµ¬ í•™ìˆ  ë°œí‘œ"),
        ("ìœ„í‚¤í”¼ë””ì•„ ì „ë¬¸ì„± ê¸°ìˆ ", "ìœ„í‚¤ í”„ë¡œí•„ ì´ë ¥"),
        ("ì „ë¬¸ ë¶„ì•¼ í‰ê°€ ê¸°ë¡", "ì „ë¬¸ì„± í‰ê°€ ì™¸ë¶€"),
        ("ìœ„ì›íšŒ í™œë™ ê¸°ë¡", "ìœ„ì›íšŒ ìë¬¸ìœ„ì› ì‹¬ì˜ìœ„ì›"),
        ("ì „ë¬¸ì„± ê´€ë ¨ ì–¸ë¡  í‰ê°€", "ì „ë¬¸ê°€ ì‹¤ë ¥íŒŒ ì—­ëŸ‰")
    ],
    "leadership": [
        ("ë²•ì•ˆ ë°œì˜ ê±´ìˆ˜", "ë²•ì•ˆ ë°œì˜ ì˜ì›ì…ë²•"),
        ("ë²•ì•ˆ í†µê³¼ìœ¨", "ë²•ì•ˆ í†µê³¼ ê°€ê²° ì„±ë¦½"),
        ("ìœ„ì›íšŒ ìœ„ì›ì¥ ê²½í—˜", "ìƒì„ìœ„ ì†Œìœ„ ìœ„ì›ì¥"),
        ("ë‹¹ì§ ê²½ë ¥", "ë‹¹ëŒ€í‘œ ì›ë‚´ëŒ€í‘œ ìµœê³ ìœ„ì›"),
        ("ì¡°ì§ í™•ëŒ€ ì‹¤ì ", "ì¡°ì§ í™•ëŒ€ ë‹¹ì› ì§€ì§€ìœ¨"),
        ("ìœ„ê¸° ëŒ€ì‘ ì‚¬ë¡€", "ìœ„ê¸°ê´€ë¦¬ ëŒ€ì‘ ìˆ˜ìŠµ"),
        ("ì •ì±… ì¶”ì§„ë ¥", "ì •ì±… ì¶”ì§„ ê´€ì²  ì„±ê³¼"),
        ("ë¦¬ë”ì‹­ ê´€ë ¨ ì–¸ë¡  í‰ê°€", "ë¦¬ë”ì‹­ ì§€ë„ë ¥ í‰ê°€"),
        ("ì˜íšŒ í˜‘ë ¥ í™œë™ ê¸°ë¡", "ì˜íšŒ í˜‘ë ¥ ì—°ëŒ€ í˜‘ìƒ"),
        ("ë¦¬ë”ì‹­ ê´€ë ¨ í‰ê°€ ê¸°ë¡", "ë¦¬ë”ì‹­ ì™¸ë¶€ í‰ê°€")
    ],
    "vision": [
        ("ì¤‘ì¥ê¸° ë°œì „ ê³„íš", "ë¹„ì „ ì¥ê¸°ê³„íš ì²­ì‚¬ì§„"),
        ("ë¯¸ë˜ íˆ¬ì ì˜ˆì‚°", "R&D êµìœ¡ ì‹ ì‚°ì—… ì˜ˆì‚°"),
        ("ì‚¬íšŒ ë°œì „ ê´€ë ¨ ì˜ˆì‚°", "í™˜ê²½ ê¸°í›„ ë³µì§€ ì˜ˆì‚°"),
        ("ê¸°ìˆ  ë°œì „ ê´€ë ¨ ì •ì±…", "ê¸°ìˆ  AI ìŠ¤ë§ˆíŠ¸ì‹œí‹° ì •ì±…"),
        ("ë¯¸ë˜ ì •ì±… ì œì•ˆ", "í˜ì‹  ë¯¸ë˜ ì •ì±… ì œì•ˆ"),
        ("ì²­ë…„ì¸µ ì •ì±…", "ì²­ë…„ ì •ì±… ë¯¸ë˜ì„¸ëŒ€"),
        ("í•´ì™¸ ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹", "í•´ì™¸ ì •ì±… ë²¤ì¹˜ë§ˆí‚¹"),
        ("ë¯¸ë˜ í‚¤ì›Œë“œ ë³´ë„", "í˜ì‹  ë¯¸ë˜ ë””ì§€í„¸ ë³´ë„"),
        ("ì¥ê¸° ê³µì•½ ì œì‹œ", "ì¥ê¸° ê³µì•½ ì§€ì† ì •ì±…"),
        ("ë¹„ì „ ê´€ë ¨ ì—°ì„¤/ê¸°ê³ ", "ë¹„ì „ ì—°ì„¤ ê¸°ê³ ë¬¸")
    ],
    "integrity": [
        ("ê¸ˆì „ ê´€ë ¨ í˜•ì‚¬ íŒê²° ë‚´ìš©", "í˜•ì‚¬ íŒê²° ë‡Œë¬¼ íš¡ë ¹ ë°°ì„"),
        ("ì¬ì‚° ì‹ ê³  ë³€ë™ í˜„í™©", "ì¬ì‚° ì‹ ê³  ë³€ë™ ì¦ê°"),
        ("ê³µì§ììœ¤ë¦¬ë²• ê´€ë ¨ ê¸°ë¡", "ê³µì§ììœ¤ë¦¬ ì‹¬ì˜ ê¸°ë¡"),
        ("ì •ì¹˜ìê¸ˆë²• ê´€ë ¨ ê¸°ë¡", "ì •ì¹˜ìê¸ˆ ì„ ê´€ìœ„ ì²˜ë¶„"),
        ("ì„ ê±°ë²• ê´€ë ¨ ê¸°ë¡", "ì„ ê±°ë²• ìœ„ë°˜ ê¸°ë¡"),
        ("ê¸ˆì „ ê´€ë ¨ ì–¸ë¡  ë³´ë„", "ê¸ˆì „ ì¬ì‚° ê´€ë ¨ ë³´ë„"),
        ("í•œêµ­íˆ¬ëª…ì„±ê¸°êµ¬ í‰ê°€", "TI Korea ì²­ë ´ë„ í‰ê°€"),
        ("ì‹œë¯¼ë‹¨ì²´ ì²­ë ´ í‰ê°€", "ì°¸ì—¬ì—°ëŒ€ ì²­ë ´ í‰ê°€"),
        ("ì •ì¹˜ìê¸ˆ ê´€ë ¨ ë³´ë„", "ì •ì¹˜ìê¸ˆ ê´€ë ¨ ë³´ë„"),
        ("ì²­ë ´ ê´€ë ¨ í‰ê°€ ê¸°ë¡", "ì²­ë ´ ì™¸ë¶€ í‰ê°€")
    ],
    "ethics": [
        ("í˜•ì‚¬ íŒê²° ê¸°ë¡", "í˜•ì‚¬ íŒê²° ë¹„ë¶€íŒ¨ ë²”ì£„"),
        ("ì„±ë¬¸ì œ ê´€ë ¨ íŒê²° ë‚´ìš©", "ì„±ë²”ì£„ íŒê²° ê¸°ë¡"),
        ("ìœ¤ë¦¬ìœ„ì›íšŒ ì‹¬ì˜ ë‚´ìš©", "ìœ¤ë¦¬ìœ„ ì‹¬ì˜ ì§•ê³„"),
        ("êµ­ê°€ì¸ê¶Œìœ„ ì‹œì •ê¶Œê³ ", "ì¸ê¶Œìœ„ ê¶Œê³  ê²°ì •"),
        ("ì €ì‘ ê´€ë ¨ ê²€ì¦ ê¸°ë¡", "ì €ì‘ í‘œì ˆ ê²€ì¦ ê¸°ë¡"),
        ("ê³µê°œ ë°œì–¸ íƒœë„ ê´€ë ¨ ë³´ë„", "ë°œì–¸ íƒœë„ ê´€ë ¨ ë³´ë„"),
        ("ì‚¬íšŒ ë°°ë ¤ ë¬¸ì œ ë°œì–¸ ê´€ë ¨ ë³´ë„", "ì°¨ë³„ ë°œì–¸ ê´€ë ¨ ë³´ë„"),
        ("í’ˆìœ„ìœ ì§€ ê´€ë ¨ ë³´ë„", "í’ˆìœ„ ê´€ë ¨ ë³´ë„"),
        ("ì‹œë¯¼ë‹¨ì²´ ìœ¤ë¦¬ í‰ê°€", "ìœ¤ë¦¬ì„± ì™¸ë¶€ í‰ê°€"),
        ("ê°€ì¡±ë¬¸ì œ ê´€ë ¨ ë³´ë„", "ê°€ì¡± ê´€ë ¨ ë³´ë„")
    ],
    "accountability": [
        ("ê³µì•½ ì´í–‰ë¥ ", "ê³µì•½ ì´í–‰ ì‹¤ì²œ ë‹¬ì„±"),
        ("íšŒì˜ ì¶œì„ë¥ ", "ì¶œì„ ë³¸íšŒì˜ ìœ„ì›íšŒ"),
        ("ì˜ˆì‚° ì§‘í–‰ë¥ ", "ì˜ˆì‚° ì§‘í–‰ ì§‘í–‰ë¥ "),
        ("ê°ì‚¬ ì§€ì  ê°œì„ ", "ê°ì‚¬ ì§€ì  ê°œì„  ì™„ë£Œ"),
        ("ë§¤ë‹ˆí˜ìŠ¤í†  í‰ê°€ ë“±ê¸‰", "ë§¤ë‹ˆí˜ìŠ¤í†  í‰ê°€ ë“±ê¸‰"),
        ("ì˜ì • í™œë™ ë³´ê³  ë¹ˆë„", "ì˜ì •í™œë™ ë³´ê³  í™œë™"),
        ("ì‹œë¯¼ë‹¨ì²´ ì˜ì • ê°ì‹œ í‰ê°€", "ì˜ì •ê°ì‹œ í‰ê°€ ì ìˆ˜"),
        ("ì§ë¬´ ìˆ˜í–‰ ê´€ë ¨ ë³´ë„", "ì§ë¬´ ìˆ˜í–‰ ê´€ë ¨ ë³´ë„"),
        ("ì±…ì„ ì´í–‰ ê´€ë ¨ ë³´ë„", "ì±…ì„ ì´í–‰ ê´€ë ¨ ë³´ë„"),
        ("ì‚¬í›„ ì±…ì„ ì´í–‰", "ì‹¤íŒ¨ ì¸ì • ê°œì„  ì´í–‰")
    ],
    "transparency": [
        ("ì •ë³´ê³µê°œ ì²­êµ¬ ì‘ë‹µë¥ ", "ì •ë³´ê³µê°œ ì‘ë‹µë¥  ì²˜ë¦¬"),
        ("íšŒì˜ë¡ ê³µê°œìœ¨", "íšŒì˜ë¡ ê³µê°œ ë¹„ìœ¨"),
        ("ì¬ì‚° ê³µê°œ ì„±ì‹¤ë„", "ì¬ì‚° ê³µê°œ ì„±ì‹¤ ê¸°ì¬"),
        ("ì˜ˆì‚° ì§‘í–‰ ìƒì„¸ ê³µê°œ", "ì˜ˆì‚° ì§‘í–‰ ì„¸ëª© ê³µê°œ"),
        ("ìë£Œ ì œì¶œ ì„±ì‹¤ì„± ê´€ë ¨ ë³´ë„", "ìë£Œ ì œì¶œ ê´€ë ¨ ë³´ë„"),
        ("ì •ë³´ê³µê°œì„¼í„° í‰ê°€", "ì •ë³´ê³µê°œ ìš°ìˆ˜ ì‚¬ë¡€"),
        ("íˆ¬ëª…ì„± ê´€ë ¨ ë³´ë„", "íˆ¬ëª… ê³µê°œ ê´€ë ¨ ë³´ë„"),
        ("ì •ë³´ê³µê°œ ê´€ë ¨ ë³´ë„", "ë¹„ê³µê°œ ì •ë³´ê³µê°œ ë³´ë„"),
        ("ì–¸ë¡  ëŒ€ì‘ íˆ¬ëª…ì„±", "ê¸°ìíšŒê²¬ ì§ˆì˜ì‘ë‹µ ì°¸ì—¬"),
        ("ì¼ì • ê³µê°œ ìˆ˜ì¤€", "ì¼ì • ê³µê°œ ì‚¬ì „ ê³µê°œ")
    ],
    "communication": [
        ("ì‹œë¯¼ ê°„ë‹´íšŒ ê°œìµœ", "ê°„ë‹´íšŒ ê°œìµœ ê±´ìˆ˜"),
        ("ê³µì²­íšŒ í† ë¡ íšŒ ê°œìµœ", "ê³µì²­íšŒ í† ë¡ íšŒ ê°œìµœ"),
        ("ê³µì‹ ì†Œí†µ ì±„ë„ ìš´ì˜", "í™ˆí˜ì´ì§€ SNS ì±„ë„"),
        ("ì‹œë¯¼ ì œì•ˆ ìˆ˜ìš©", "ì œì•ˆ ìˆ˜ìš© ê±´ìˆ˜ ë¹„ìœ¨"),
        ("SNS ì†Œí†µ í™œë™", "SNS ì†Œí†µ íŒ”ë¡œì›Œ ì°¸ì—¬"),
        ("SNS ëŒ“ê¸€ ì‘ë‹µ", "ëŒ“ê¸€ ì‘ë‹µ ê±´ìˆ˜ ë¹„ìœ¨"),
        ("í† ë¡  ì°¸ì—¬ í‰ê°€", "í† ë¡  ëŠ¥ë ¥ í‰ê°€"),
        ("ì†Œí†µ ì ê·¹ì„± ê´€ë ¨ ë³´ë„", "ì†Œí†µ ê´€ë ¨ ë³´ë„"),
        ("ê²½ì²­ ìì„¸ í‰ê°€", "ê²½ì²­ ê³µê° í‰ê°€"),
        ("ì†Œí†µ ê´€ë ¨ í‰ê°€ ê¸°ë¡", "ì†Œí†µ ì™¸ë¶€ í‰ê°€")
    ],
    "responsiveness": [
        ("ì£¼ë¯¼ì°¸ì—¬ì˜ˆì‚° ê·œëª¨", "ì°¸ì—¬ì˜ˆì‚° ê¸ˆì•¡ ê·œëª¨"),
        ("ì •ë³´ê³µê°œ ì²˜ë¦¬ ê¸°ê°„", "ì •ë³´ê³µê°œ ì²˜ë¦¬ ì¼ìˆ˜"),
        ("ì£¼ë¯¼ ì œì•ˆ ë°˜ì˜", "ì œì•ˆ ë°˜ì˜ ê±´ìˆ˜ ë¹„ìœ¨"),
        ("ì§€ì—­ í˜„ì•ˆ ëŒ€ì‘", "í˜„ì¥ ì ê²€ ëŒ€ì±… ë°œí‘œ"),
        ("ì¬ë‚œ ëŒ€ì‘ ì‹¤ì ", "ì¬ë‚œ ëŒ€ì‘ í˜„ì¥ í‰ê°€"),
        ("ìœ„ê¸° ëŒ€ì‘ ë³´ë„", "ìœ„ê¸° ì¬ë‚œ ëŒ€ì‘ ë³´ë„"),
        ("í˜„ì¥ ë°©ë¬¸ ë³´ë„", "í˜„ì¥ ë°©ë¬¸ ê´€ë ¨ ë³´ë„"),
        ("ë¯¼ì› ì²˜ë¦¬ ë§Œì¡±ë„", "ë¯¼ì› ì²˜ë¦¬ ë§Œì¡±ë„"),
        ("ëŒ€ì‘ ì†ë„ ê´€ë ¨ ë³´ë„", "ëŒ€ì‘ ì†ë„ ê´€ë ¨ ë³´ë„"),
        ("í˜„ì¥ ëŒ€ì‘ ê´€ë ¨ ë³´ë„", "í˜„ì¥ ëŒ€ì‘ ê´€ë ¨ ë³´ë„")
    ],
    "publicinterest": [
        ("ì‚¬íšŒë³µì§€ ì˜ˆì‚° ë¹„ìœ¨", "ë³µì§€ ì˜ˆì‚° ë¹„ìœ¨"),
        ("ì·¨ì•½ê³„ì¸µ ì§€ì› í”„ë¡œê·¸ë¨", "ì·¨ì•½ê³„ì¸µ ì¥ì•  ë…¸ì¸ ì•„ë™"),
        ("í™˜ê²½ ê¸°í›„ ì˜ˆì‚°", "í™˜ê²½ ì˜ˆì‚° ê¸°í›„ ë…¹ìƒ‰"),
        ("ì§€ì—­ ê· í˜• ë°œì „ ì˜ˆì‚°", "ê· í˜•ë°œì „ ì§€ì—­ íˆ¬ì"),
        ("ê³µìµ í™œë™ ë³´ë„", "ë´‰ì‚¬ ì·¨ì•½ê³„ì¸µ ë³´ë„"),
        ("ì‚¬íšŒê³µí—Œ SNS ê²Œì‹œ", "ê³µìµ ê²Œì‹œë¬¼ ì‚¬íšŒê³µí—Œ"),
        ("ê³µìµ ë²•ì•ˆ ë°œì˜", "ê³µìµ ë²•ì•ˆ ë°œì˜ ì‹¤ì "),
        ("ì´ìµ ìƒì¶© ê´€ë ¨ ë³´ë„", "ì´ìµ ìƒì¶© ê´€ë ¨ ë³´ë„"),
        ("ì§€ì—­ ê· í˜• ê´€ë ¨ ë³´ë„", "ì§€ì—­ ê· í˜• ê´€ë ¨ ë³´ë„"),
        ("ê³µìµ ê´€ë ¨ í‰ê°€ ê¸°ë¡", "ê³µìµ ì™¸ë¶€ í‰ê°€")
    ]
}


def get_exact_count(table_name, filters=None):
    """ì •í™•í•œ ê°œìˆ˜ ì¡°íšŒ"""
    try:
        query = supabase.table(table_name).select('*', count='exact')
        if filters:
            for key, value in filters.items():
                if value is not None:
                    query = query.eq(key, value)
        response = query.limit(1).execute()
        return response.count if response.count else 0
    except Exception as e:
        print(f"  âš ï¸ count ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0


def normalize_date(date_str):
    """ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”, ì‹¤íŒ¨ì‹œ None ë°˜í™˜"""
    if not date_str or not isinstance(date_str, str):
        return None

    date_str = date_str.strip()

    # ëª…í™•íˆ ì˜ëª»ëœ ê°’
    if 'ë¯¸ìƒ' in date_str or 'ë¶ˆëª…' in date_str or 'ì—†ìŒ' in date_str:
        return None

    import re

    # YYYY-MM-DD í˜•ì‹ ì²´í¬
    match = re.match(r'^(\d{4})-(\d{2})-(\d{2})$', date_str)
    if match:
        year, month, day = match.groups()
        # ì˜ëª»ëœ ì›”/ì¼ ë³´ì • (00 â†’ 01)
        month = int(month) if int(month) > 0 else 1
        day = int(day) if int(day) > 0 else 1
        # ì›”/ì¼ ë²”ìœ„ ê²€ì¦
        month = min(month, 12)
        day = min(day, 28)  # ì•ˆì „í•˜ê²Œ 28ì¼ë¡œ ì œí•œ
        return f"{year}-{month:02d}-{day:02d}"

    # YYYY-MM (ì›”ê¹Œì§€ë§Œ ìˆìŒ) -> YYYY-MM-01ë¡œ ë³€í™˜
    match = re.match(r'^(\d{4})-(\d{1,2})$', date_str)
    if match:
        year, month = match.groups()
        month = int(month) if int(month) > 0 else 1
        month = min(month, 12)
        return f"{year}-{month:02d}-01"

    # YYYY (ë…„ë„ë§Œ) -> YYYY-01-01ë¡œ ë³€í™˜
    if re.match(r'^\d{4}$', date_str):
        return f"{date_str}-01-01"

    # ê¸°íƒ€ í˜•ì‹ì€ ë¬´ì‹œ
    return None


def check_politician_exists(politician_id):
    """ì •ì¹˜ì¸ ID í™•ì¸"""
    try:
        result = supabase.table('politicians').select('id, name').eq('id', politician_id).execute()
        if result.data and len(result.data) > 0:
            return True, result.data[0].get('name', '')
        return False, None
    except Exception as e:
        print(f"âŒ ì •ì¹˜ì¸ í™•ì¸ ì—ëŸ¬: {e}")
        return False, None


def init_ai_client(ai_name):
    """AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global ai_clients

    if ai_name in ai_clients:
        return ai_clients[ai_name]

    config = AI_CONFIGS.get(ai_name)
    if not config:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” AI: {ai_name}")

    api_key = os.getenv(config['env_key'])
    if not api_key:
        raise ValueError(f"{config['env_key']} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if ai_name == "Perplexity":
        from openai import OpenAI
        ai_clients[ai_name] = OpenAI(
            api_key=api_key,
            base_url=config['base_url']
        )
    elif ai_name == "Claude":
        import anthropic
        ai_clients[ai_name] = anthropic.Anthropic(api_key=api_key)
    elif ai_name == "ChatGPT":
        from openai import OpenAI
        ai_clients[ai_name] = OpenAI(api_key=api_key)
    elif ai_name == "Grok":
        from openai import OpenAI
        ai_clients[ai_name] = OpenAI(
            api_key=api_key,
            base_url=config['base_url']
        )
    elif ai_name == "Gemini":
        from google import genai
        client = genai.Client(api_key=api_key)
        ai_clients[ai_name] = client

    return ai_clients[ai_name]


def get_date_range():
    """V30 ê¸°ê°„ ì œí•œ ê³„ì‚°"""
    evaluation_date = datetime.now()
    official_start = evaluation_date - timedelta(days=365*4)  # 4ë…„
    public_start = evaluation_date - timedelta(days=365*2)    # 2ë…„

    return {
        'evaluation_date': evaluation_date.strftime('%Y-%m-%d'),
        'official_start': official_start.strftime('%Y-%m-%d'),
        'official_end': evaluation_date.strftime('%Y-%m-%d'),
        'public_start': public_start.strftime('%Y-%m-%d'),
        'public_end': evaluation_date.strftime('%Y-%m-%d'),
    }


def build_prompt_v30(politician_name, category_name, category_korean, data_type, count, sentiment_dist, ai_name):
    """V30 ìˆ˜ì§‘ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    date_range = get_date_range()

    if data_type == "official":
        date_start = date_range['official_start']
        date_end = date_range['official_end']
        period_desc = "ìµœê·¼ 4ë…„"
    else:
        date_start = date_range['public_start']
        date_end = date_range['public_end']
        period_desc = "ìµœê·¼ 2ë…„"

    # ê°ì„± ë¶„í¬ ì„¤ëª…
    negative_count = sentiment_dist.get('negative', 0)
    positive_count = sentiment_dist.get('positive', 0)
    neutral_count = sentiment_dist.get('neutral', 0)

    # AIë³„ ì—­í•  ì„¤ëª…
    if ai_name == "Perplexity":
        role_desc = "ê²€ìƒ‰ ì „ë¬¸ AIë¡œì„œ ê³µì‹ ë°ì´í„°ì™€ ë‰´ìŠ¤ë¥¼ ì „ë‹´ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        if data_type == "official":
            search_instruction = f"""
ê³µì‹ í™œë™ ë°ì´í„° ìˆ˜ì§‘ ì§€ì¹¨:
âœ… ìˆ˜ì§‘ ëŒ€ìƒ (ìš°ì„ ìˆœìœ„):
1. êµ­íšŒ ì˜ì •í™œë™: ë²•ì•ˆ ë°œì˜, êµ­ì •ê°ì‚¬, ìœ„ì›íšŒ í™œë™, ëŒ€ì •ë¶€ì§ˆë¬¸
2. ê³µì‹ ë°œí‘œ: ê¸°ìíšŒê²¬, ì„±ëª…ì„œ, ê³µì•½, ì •ì±… ë°œí‘œ
3. ê³µì  ê¸°ë¡: ê²½ë ¥, í•™ë ¥, ìˆ˜ìƒ, ì„ëª…
4. ì–¸ë¡  ë³´ë„: ìœ„ ê³µì‹ í™œë™ì— ëŒ€í•œ ì–¸ë¡  ê¸°ì‚¬ë„ í¬í•¨!

âš ï¸ í•µì‹¬: ê³µì‹ 'ë„ë©”ì¸'ì´ ì•„ë‹ˆë¼ ê³µì‹ 'í™œë™'ì´ ì¤‘ìš”í•©ë‹ˆë‹¤!
- êµ­íšŒì˜ì›ì˜ ë²•ì•ˆ ë°œì˜ë¥¼ ë³´ë„í•œ ë‰´ìŠ¤ ê¸°ì‚¬ â†’ âœ… ê³µì‹ ë°ì´í„°ë¡œ ì¸ì •
- ì •ì¹˜ì¸ì˜ ê³µì‹ ê²½ë ¥ì„ ì •ë¦¬í•œ ë‚˜ë¬´ìœ„í‚¤ â†’ âœ… ê³µì‹ ë°ì´í„°ë¡œ ì¸ì •
- ì •ë‹¹ ê³µì‹ ë°œí‘œë¥¼ ë³´ë„í•œ ê¸°ì‚¬ â†’ âœ… ê³µì‹ ë°ì´í„°ë¡œ ì¸ì •

ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì°¾ì€ ë°ì´í„°ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•˜ì„¸ìš”!
ë¹ˆ ë°°ì—´([])ì„ ë°˜í™˜í•˜ì§€ ë§ˆì„¸ìš”!
"""
        else:
            search_instruction = """
ë‰´ìŠ¤ ì „ë‹´ ìˆ˜ì§‘ ì§€ì¹¨:
- ì£¼ìš” ì–¸ë¡ ì‚¬: ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´, í•œê²¨ë ˆ, ê²½í–¥ì‹ ë¬¸
- ë°©ì†¡ì‚¬: KBS, MBC, SBS, JTBC, TVì¡°ì„ , MBN
- í†µì‹ ì‚¬: ì—°í•©ë‰´ìŠ¤, ë‰´ì‹œìŠ¤, ë‰´ìŠ¤1
- ê²½ì œì§€: ë§¤ì¼ê²½ì œ, í•œêµ­ê²½ì œ
- ë°˜ë“œì‹œ ì‹¤ì œ ë‰´ìŠ¤ URL í¬í•¨
"""
    elif ai_name == "Claude":
        role_desc = "ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹°, ì‹œì‚¬ë§¤ê±°ì§„ ì „ë¬¸ìœ¼ë¡œ ì—¬ë¡ ê³¼ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        search_instruction = """
ìˆ˜ì§‘ ëŒ€ìƒ (ë‰´ìŠ¤ ì œì™¸):
1. ë¸”ë¡œê·¸/ì¹¼ëŸ¼: ë„¤ì´ë²„ ë¸”ë¡œê·¸, ë¸ŒëŸ°ì¹˜, ë‹¤ìŒ ë¸”ë¡œê·¸, ì „ë¬¸ê°€ ì¹¼ëŸ¼
2. ì»¤ë®¤ë‹ˆí‹°: ë„¤ì´ë²„ ì¹´í˜, ë””ì‹œì¸ì‚¬ì´ë“œ, í´ë¦¬ì•™, ì—í¨ì½”ë¦¬ì•„, ë‚˜ë¬´ìœ„í‚¤
3. ì‹œì‚¬ë§¤ê±°ì§„: ì‹œì‚¬IN, í•œê²¨ë ˆ21, ì£¼ê°„ê²½í–¥, ë¯¸ë””ì–´ì˜¤ëŠ˜, í”„ë ˆì‹œì•ˆ

web_search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê²Œì‹œë¬¼/ê¸°ì‚¬ë¥¼ ì°¾ìœ¼ì„¸ìš”.
ì»¤ë®¤ë‹ˆí‹° ì—¬ë¡ , ë¸”ë¡œê±° ë¶„ì„, ì‹¬ì¸µ ê¸°íš ê¸°ì‚¬ ì¤‘ì‹¬ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""
    elif ai_name == "Gemini":
        role_desc = "ì˜ìƒë§¤ì²´, ê¸€ë¡œë²Œ/ì™¸ì‹ , ìœ„í‚¤í”¼ë””ì•„ ì „ë¬¸ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        search_instruction = """
ìˆ˜ì§‘ ëŒ€ìƒ (êµ­ë‚´ ë‰´ìŠ¤ ì œì™¸):
1. ì˜ìƒë§¤ì²´: ìœ íŠœë¸Œ (ì •ì¹˜ì¸ ì±„ë„, ì¸í„°ë·°, í† ë¡ íšŒ ì˜ìƒ), íŒŸìºìŠ¤íŠ¸
2. ê¸€ë¡œë²Œ/ì™¸ì‹ : ë¡œì´í„°, AP, AFP, BBC, CNN (í•œêµ­ ì •ì¹˜ ê´€ë ¨)
3. ë°±ê³¼ì‚¬ì „: ìœ„í‚¤í”¼ë””ì•„ (ì˜ë¬¸/í•œê¸€)

Google Searchë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì˜ìƒ/ê¸°ì‚¬/ë¬¸ì„œë¥¼ ì°¾ìœ¼ì„¸ìš”.
ìœ íŠœë¸Œ ì˜ìƒ URL, ì™¸ì‹  ê¸°ì‚¬ URL, ìœ„í‚¤í”¼ë””ì•„ URLì„ í¬í•¨í•˜ì„¸ìš”.
"""
    elif ai_name == "Grok":
        role_desc = "X(íŠ¸ìœ„í„°) ì „ë‹´ìœ¼ë¡œ ì •ì¹˜ì¸ ê´€ë ¨ íŠ¸ìœ—ê³¼ ë°˜ì‘ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        search_instruction = """
X(íŠ¸ìœ„í„°) ì „ë‹´ ìˆ˜ì§‘ - ë”± 2ê°€ì§€:
1. ì •ì¹˜ì¸ ê´€ë ¨ íŠ¸ìœ—: X ì´ìš©ìë“¤ì´ í•´ë‹¹ ì •ì¹˜ì¸ì— ëŒ€í•´ ì“´ íŠ¸ìœ—
2. ì •ì¹˜ì¸ íŠ¸ìœ—ì— ëŒ€í•œ ë°˜ì‘: í•´ë‹¹ ì •ì¹˜ì¸ì´ ì˜¬ë¦° íŠ¸ìœ—ì— ëŒ€í•œ ì´ìš©ì ë°˜ì‘ (ëŒ“ê¸€, ì¸ìš©)

ì¶œì²˜ í˜•ì‹: "X/@ê³„ì •ëª…" ë˜ëŠ” íŠ¸ìœ— URL
"""
    else:
        role_desc = "ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        search_instruction = ""

    # Perplexityìš© í”„ë¡¬í”„íŠ¸ëŠ” ë” ìì—°ìŠ¤ëŸ½ê²Œ
    if ai_name == "Perplexity":
        prompt = f"""
{politician_full}ì˜ {category_korean}({category_name}) ê´€ë ¨ í™œë™ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ ì¡°ê±´:
- ê¸°ê°„: {date_start} ~ {date_end}
- ê°œìˆ˜: ìµœëŒ€ {count}ê°œ
- ë‚´ìš©: {"ì˜ì •í™œë™, ë²•ì•ˆë°œì˜, ê³µì‹ê²½ë ¥, ê³µì í™œë™" if data_type == "official" else "ë‰´ìŠ¤ê¸°ì‚¬, ì–¸ë¡ ë³´ë„, ì¸í„°ë·°"}

ê²°ê³¼ë¥¼ JSON ë°°ì—´ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
```json
[
  {{
    "title": "ì œëª©",
    "content": "ë‚´ìš© ìš”ì•½ (100-200ì)",
    "source": "ì¶œì²˜ëª…",
    "source_url": "URL",
    "date": "YYYY-MM-DD"
  }}
]
```

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ URLê³¼ í•¨ê»˜ JSONìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
"""
    else:
        prompt = f"""
## ê²€ìƒ‰ ìš”ì²­
{politician_name}({category_korean}) ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

{role_desc}

## ê²€ìƒ‰ ì¡°ê±´
- ì¹´í…Œê³ ë¦¬: {category_name} ({category_korean})
- ìœ í˜•: {data_type.upper()}
- ê°œìˆ˜: {count}ê°œ
- ê¸°ê°„: {date_start} ~ {date_end}

{search_instruction}

## í•µì‹¬ ê·œì¹™
1. ì›¹ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ê¸°ì‚¬/ê²Œì‹œë¬¼ì„ ì°¾ìœ¼ì„¸ìš”
2. ì‹¤ì œ URL í•„ìˆ˜ í¬í•¨
3. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ ìƒì„± ê¸ˆì§€

## JSON ì¶œë ¥ í˜•ì‹
```json
[
  {{
    "title": "ì œëª© (20ì ì´ë‚´)",
    "content": "ë‚´ìš© (100-300ì)",
    "source": "ì¶œì²˜ëª…",
    "source_url": "https://...",
    "date": "YYYY-MM-DD",
    "sentiment": "positive/negative/neutral"
  }}
]
```

{count}ê°œì˜ {category_korean} ê´€ë ¨ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
"""
    return prompt


def call_perplexity(client, prompt, data_type):
    """Perplexity API í˜¸ì¶œ (Sonar - ê²€ìƒ‰ ë‚´ì¥)"""
    config = AI_CONFIGS["Perplexity"]

    # ê³µì‹ ë°ì´í„°ëŠ” í”„ë¡¬í”„íŠ¸ì—ì„œ ë„ë©”ì¸ í•„í„° ì§€ì‹œ
    # Perplexity APIëŠ” search_domain_filter ëŒ€ì‹  í”„ë¡¬í”„íŠ¸ë¡œ ì œì–´
    messages = [{"role": "user", "content": prompt}]

    try:
        response = client.chat.completions.create(
            model=config['model'],
            messages=messages,
            max_tokens=8000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"  âŒ Perplexity API ì—ëŸ¬: {e}")
        return None


def call_claude_with_websearch(client, prompt):
    """Claude API í˜¸ì¶œ (web_search tool ì‚¬ìš©)"""
    config = AI_CONFIGS["Claude"]

    try:
        # beta ê¸°ëŠ¥ì€ client.beta.messages.create() ì‚¬ìš©
        response = client.beta.messages.create(
            model=config['model'],
            max_tokens=8000,
            betas=["web-search-2025-03-05"],
            tools=[
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": 15
                }
            ],
            messages=[{"role": "user", "content": prompt}]
        )

        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (BetaTextBlockë§Œ)
        result_text = ""
        for block in response.content:
            block_type = type(block).__name__
            # BetaTextBlockì—ì„œë§Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (BetaWebSearchResultBlock ë“± ì œì™¸)
            if block_type == 'BetaTextBlock' and hasattr(block, 'text'):
                result_text += block.text

        if not result_text:
            print(f"    [DEBUG] ì‘ë‹µ ë¸”ë¡: {[type(b).__name__ for b in response.content]}")

        return result_text if result_text else None
    except Exception as e:
        print(f"  âŒ Claude API ì—ëŸ¬: {e}")
        return None


def call_gemini_with_search(client, prompt):
    """Gemini API í˜¸ì¶œ (Google Search grounding) - ì‹ ê·œ SDK + URL ê²€ì¦"""
    try:
        from google import genai
        from google.genai import types

        # Gemini 2.0+ google_search ë„êµ¬ ì‚¬ìš©
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
        )

        if not response.text:
            return None

        # âœ… grounding_metadata í™•ì¸: ì‹¤ì œ ê²€ìƒ‰í•œ URL ì¶”ì¶œ
        actual_urls = []
        if hasattr(response, 'grounding_metadata') and response.grounding_metadata:
            grounding = response.grounding_metadata
            if hasattr(grounding, 'grounding_chunks') and grounding.grounding_chunks:
                for chunk in grounding.grounding_chunks:
                    if hasattr(chunk, 'web') and hasattr(chunk.web, 'uri'):
                        actual_urls.append(chunk.web.uri)

            if actual_urls:
                print(f"    [Gemini] ì‹¤ì œ ê²€ìƒ‰ URL: {len(actual_urls)}ê°œ")
            else:
                print(f"    [Gemini] âš ï¸ grounding_chunks ì—†ìŒ - ê²€ìƒ‰ ë¯¸ìˆ˜í–‰")

        # JSON íŒŒì‹± ë° ê°€ì§œ URL í•„í„°ë§
        if actual_urls:
            try:
                items = json.loads(response.text)
                if isinstance(items, list):
                    verified_items = []
                    fake_count = 0
                    for item in items:
                        url = item.get('source_url', '')
                        # URLì´ ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ”ì§€ í™•ì¸
                        if url and url in actual_urls:
                            verified_items.append(item)
                        else:
                            fake_count += 1
                            # ì‹¤ì œ URLë¡œ êµì²´ ì‹œë„ (ì²« ë²ˆì§¸ URL ì‚¬ìš©)
                            if actual_urls:
                                item['source_url'] = actual_urls[0]
                                verified_items.append(item)

                    if fake_count > 0:
                        print(f"    [Gemini] ê°€ì§œ URL {fake_count}ê°œ ë°œê²¬ â†’ ì‹¤ì œ URLë¡œ êµì²´")

                    return json.dumps(verified_items, ensure_ascii=False)
            except json.JSONDecodeError:
                pass  # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

        return response.text
    except Exception as e:
        print(f"  âŒ Gemini API ì—ëŸ¬: {e}")
        # fallback ì—†ì´ ì—ëŸ¬ ë°˜í™˜ (í™˜ê° ë°©ì§€)
        return None


def call_grok(client, prompt):
    """Grok API í˜¸ì¶œ (X/Twitter ì ‘ê·¼)"""
    config = AI_CONFIGS["Grok"]

    try:
        response = client.chat.completions.create(
            model=config['model'],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=8000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"  âŒ Grok API ì—ëŸ¬: {e}")
        return None


def call_ai(ai_name, client, prompt, data_type="public"):
    """AIë³„ í˜¸ì¶œ í†µí•© í•¨ìˆ˜"""
    if ai_name == "Claude":
        return call_claude_with_websearch(client, prompt)
    elif ai_name == "Gemini":
        return call_gemini_with_search(client, prompt)
    elif ai_name == "Perplexity":
        return call_perplexity(client, prompt, data_type)
    elif ai_name == "Grok":
        return call_grok(client, prompt)
    return None


def build_search_prompt(ai_name, data_type, topic_mode, politician_full, item_keywords, remaining, year_hint="", extra_keyword=""):
    """AIë³„, ë°ì´í„°íƒ€ì…ë³„, ì£¼ì œë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        topic_mode: 'negative' (ë¶€ì •), 'positive' (ê¸ì •), 'free' (ììœ )
    """

    # topic_modeë³„ ì§€ì‹œë¬¸
    if topic_mode == 'negative':
        topic_instruction = """
ğŸš¨ **ë¶€ì •ì  ì£¼ì œë§Œ ìˆ˜ì§‘** ğŸš¨
ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ ë¶€ì •ì ì¸ ë‚´ìš©ë§Œ ê²€ìƒ‰í•˜ì„¸ìš”:
- ë…¼ë€, ë¹„íŒ, ì˜í˜¹, ìŠ¤ìº”ë“¤
- ì‹¤íŒ¨, ì‹¤ì •, ë¬´ëŠ¥
- ìœ„ë²• í–‰ìœ„, ìœ¤ë¦¬ ìœ„ë°˜
- ê³µì•½ ë¶ˆì´í–‰, ì •ì±… ì‹¤íŒ¨
- ì–¸ë¡ /ì‹œë¯¼ ë¹„íŒ

ê¸ì •ì  ë‚´ìš©ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!
"""
    elif topic_mode == 'positive':
        topic_instruction = """
âœ¨ **ê¸ì •ì  ì£¼ì œë§Œ ìˆ˜ì§‘** âœ¨
ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ ê¸ì •ì ì¸ ë‚´ìš©ë§Œ ê²€ìƒ‰í•˜ì„¸ìš”:
- ì„±ê³¼, ì—…ì , ìˆ˜ìƒ
- ê³µì•½ ì´í–‰, ì •ì±… ì„±ê³µ
- ë²•ì•ˆ í†µê³¼, ê°œí˜ ì„±ê³¼
- í‘œì°½, ê¸ì • í‰ê°€
- ì‹œë¯¼ ë§Œì¡±ë„ ìƒìŠ¹

ë¶€ì •ì  ë‚´ìš©ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!
"""
    else:  # free
        topic_instruction = """
ğŸ² **ììœ  ì£¼ì œ (ê¸ì •/ë¶€ì • ë¬´ê´€)** ğŸ²
ê¸ì •ë„ ë¶€ì •ë„ ì•„ë‹Œ ì¤‘ë¦½ì  í™œë™ í¬í•¨:
- ì˜ì • í™œë™, íšŒì˜ ì°¸ì„
- ì¼ë°˜ì ì¸ ë°œì–¸, ê³µì‹ í–‰ì‚¬
- ê¸ì •/ë¶€ì • ìƒê´€ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬´ì‘ìœ„ë¡œ ìˆ˜ì§‘

âš ï¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëœë¤í•˜ê²Œ ì„ íƒí•˜ì„¸ìš”!
"""

    if data_type == "official":
        if ai_name == "Claude":
            return f"""Search the web for: {politician_full} {item_keywords} {extra_keyword} {year_hint} ê³µì‹

ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ {politician_full} ê´€ë ¨ ê³µì‹ í™œë™ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

ê²€ìƒ‰ ëŒ€ìƒ (ê³µì‹ í™œë™):
- êµ­íšŒ ì˜ì •í™œë™: ë²•ì•ˆ ë°œì˜, êµ­ì •ê°ì‚¬, ìœ„ì›íšŒ í™œë™
- ê³µì‹ ë°œí‘œ: ê¸°ìíšŒê²¬, ì„±ëª…ì„œ, ê³µì•½, ì •ì±… ë°œí‘œ
- ê³µì  ê¸°ë¡: ê²½ë ¥, í•™ë ¥, ìˆ˜ìƒ, ì„ëª…

ê²€ìƒ‰ ì¡°ê±´:
- ê¸°ê°„: 2022ë…„ 1ì›” ~ 2026ë…„ 1ì›” (íŠ¹íˆ {year_hint} ì¤‘ì‹¬)
- ê°œìˆ˜: {min(remaining, 5)}ê°œ
- ë°˜ë“œì‹œ web_search ë„êµ¬ ì‚¬ìš©

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
[{{"title": "ì œëª©", "content": "ë‚´ìš© ìš”ì•½", "source": "ì¶œì²˜", "source_url": "URL", "date": "2024-01-15"}}]

ì¤‘ìš”: ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ê³  ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        elif ai_name == "Gemini":
            return f"""{politician_full} {item_keywords} {extra_keyword} {year_hint}

ìœ„ í‚¤ì›Œë“œë¡œ {politician_full} ê´€ë ¨ ê³µì‹ í™œë™ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

{topic_instruction}

ê²€ìƒ‰ ëŒ€ìƒ (ê³µì‹ í™œë™):
- êµ­íšŒ ì˜ì •í™œë™: ë²•ì•ˆ ë°œì˜, êµ­ì •ê°ì‚¬, ìœ„ì›íšŒ í™œë™
- ê³µì‹ ë°œí‘œ: ê¸°ìíšŒê²¬, ì„±ëª…ì„œ, ê³µì•½
- ê³µì  ê¸°ë¡: ê²½ë ¥, í•™ë ¥, ìˆ˜ìƒ

ê²€ìƒ‰ ì¡°ê±´:
- ê¸°ê°„: 2022ë…„ 1ì›” ~ 2026ë…„ 1ì›” (íŠ¹íˆ {year_hint} ì¤‘ì‹¬)
- ê°œìˆ˜: {min(remaining, 5)}ê°œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
[{{"title": "ì œëª©", "content": "ë‚´ìš© ìš”ì•½", "source": "ì¶œì²˜", "source_url": "URL", "date": "2024-01-15"}}]"""
    else:  # public
        if ai_name == "Claude":
            return f"""Search the web for: {politician_full} {item_keywords}

ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ {politician_full} ê´€ë ¨ ë‰´ìŠ¤/ì–¸ë¡  ë³´ë„ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

ê²€ìƒ‰ í•„ìˆ˜ ì¡°ê±´:
- ë°˜ë“œì‹œ web_search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
- ê¸°ê°„: 2024ë…„ 1ì›” ~ 2026ë…„ 1ì›” (ìµœê·¼ 2ë…„)
- ê°œìˆ˜: {min(remaining, 5)}ê°œ
- ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë‰´ìŠ¤ URLë§Œ í¬í•¨

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
[{{"title": "ê¸°ì‚¬ ì œëª©", "content": "ë‚´ìš© ìš”ì•½ (100ì ì´ë‚´)", "source": "ì–¸ë¡ ì‚¬ëª…", "source_url": "ì‹¤ì œ ê¸°ì‚¬ URL", "date": "2024-06-15"}}]

ì¤‘ìš”: ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ê³  ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        elif ai_name == "Perplexity":
            # Perplexity: êµ­ë‚´ì™¸ ë‰´ìŠ¤/ì–¸ë¡  ì „ë‹´! (SNS, X ê¸ˆì§€)
            return f"""{politician_full} {item_keywords} ë‰´ìŠ¤ ê²€ìƒ‰

ã€Perplexity ë‹´ë‹¹: êµ­ë‚´ì™¸ ë‰´ìŠ¤/ì–¸ë¡  ì „ë‹´!ã€‘

ìœ„ í‚¤ì›Œë“œë¡œ {politician_full} ê´€ë ¨ ë‰´ìŠ¤/ì–¸ë¡  ë³´ë„ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

{topic_instruction}

âœ… ìˆ˜ì§‘ ëŒ€ìƒ (êµ­ë‚´ì™¸ ë‰´ìŠ¤/ì–¸ë¡ ):
- êµ­ë‚´ ì‹ ë¬¸: ì¡°ì„ ì¼ë³´, ì¤‘ì•™ì¼ë³´, ë™ì•„ì¼ë³´, í•œê²¨ë ˆ, ê²½í–¥ì‹ ë¬¸
- ë°©ì†¡ì‚¬: KBS, MBC, SBS, JTBC, TVì¡°ì„ , MBN
- í†µì‹ ì‚¬: ì—°í•©ë‰´ìŠ¤, ë‰´ì‹œìŠ¤, ë‰´ìŠ¤1
- ê²½ì œì§€: ë§¤ì¼ê²½ì œ, í•œêµ­ê²½ì œ
- ì™¸ì‹ : ë¡œì´í„°, AP, AFP, BBC, CNN, NHK ë“± ê¸€ë¡œë²Œ ë§¤ì²´

ğŸš« ìˆ˜ì§‘ ê¸ˆì§€:
- âŒ SNS (Facebook, Instagram, YouTube)
- âŒ X(íŠ¸ìœ„í„°)
- âŒ ë¸”ë¡œê·¸, ì¹´í˜, ìœ„í‚¤

ê¸°ê°„: 2024ë…„ 1ì›” ~ 2026ë…„ 1ì›”
ê°œìˆ˜: {min(remaining, 5)}ê°œ

JSON í˜•ì‹:
[{{"title": "ì œëª©", "content": "ë‚´ìš© ìš”ì•½", "source": "ì¶œì²˜", "source_url": "URL", "date": "2024-06-15"}}]"""
        elif ai_name == "Gemini":
            # Gemini PUBLIC: ë‰´ìŠ¤/X ì œì™¸ ì „ë¶€ (SNS, ìœ„í‚¤, ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹°)
            return f"""{politician_full} {item_keywords} ê²€ìƒ‰

ã€Gemini ë‹´ë‹¹: ë‰´ìŠ¤/X ì œì™¸ ì „ë¶€ã€‘

ìœ„ í‚¤ì›Œë“œë¡œ {politician_full} ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

{topic_instruction}

âœ… ìˆ˜ì§‘ ëŒ€ìƒ:
- SNS: ìœ íŠœë¸Œ(ì˜ìƒ, ì¸í„°ë·°), ì¸ìŠ¤íƒ€ê·¸ë¨, í˜ì´ìŠ¤ë¶
- ìœ„í‚¤í”¼ë””ì•„: í•œê¸€/ì˜ë¬¸ ìœ„í‚¤í”¼ë””ì•„
- ë¸”ë¡œê·¸/ì¹¼ëŸ¼: ë„¤ì´ë²„ ë¸”ë¡œê·¸, ë¸ŒëŸ°ì¹˜, ì „ë¬¸ê°€ ì¹¼ëŸ¼
- ì»¤ë®¤ë‹ˆí‹°: ë‚˜ë¬´ìœ„í‚¤, ë„¤ì´ë²„ ì¹´í˜, í´ë¦¬ì•™

ğŸš« ìˆ˜ì§‘ ê¸ˆì§€:
- âŒ ë‰´ìŠ¤/ì–¸ë¡  (êµ­ë‚´ì™¸ ëª¨ë‘ â†’ Perplexity ë‹´ë‹¹!)
- âŒ X(íŠ¸ìœ„í„°) â†’ Grok ë‹´ë‹¹!
- âŒ example.com ê°™ì€ ê°€ì§œ URL ìƒì„± ê¸ˆì§€!

ê¸°ê°„: 2024ë…„ 1ì›” ~ 2026ë…„ 1ì›”
ê°œìˆ˜: {min(remaining, 5)}ê°œ

JSON í˜•ì‹:
[{{"title": "ì œëª©", "content": "ë‚´ìš© ìš”ì•½", "source": "ì¶œì²˜ëª…", "source_url": "ì‹¤ì œ URL", "date": "2024-06-15"}}]

ì¤‘ìš”: ë°˜ë“œì‹œ ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì˜ URLë§Œ ì‚¬ìš©í•˜ì„¸ìš”!"""
        elif ai_name == "Grok":
            # Grok: X/íŠ¸ìœ„í„°ë§Œ! (ë‰´ìŠ¤, SNS ê¸ˆì§€)
            return f"""ë‹¤ìŒ ì •ì¹˜ì¸ì— ëŒ€í•œ X(íŠ¸ìœ„í„°) ê²Œì‹œë¬¼ {min(remaining, 5)}ê°œë¥¼ JSON ë°°ì—´ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

{topic_instruction}

ì •ì¹˜ì¸: {politician_full}
í‚¤ì›Œë“œ: {item_keywords}

JSON í˜•ì‹:
```json
[
  {{"title": "íŠ¸ìœ— ìš”ì•½", "content": "íŠ¸ìœ— ë‚´ìš©", "source": "X", "source_url": "X/@ê³„ì •ëª…", "date": "2024-06-15"}}
]
```

ì§€ê¸ˆ ë°”ë¡œ JSON ë°°ì—´ì„ ì¶œë ¥í•˜ì„¸ìš”:"""
    return None


def extract_url(item):
    """ì•„ì´í…œì—ì„œ URL ì¶”ì¶œ (íƒ€ì… ì•ˆì „)"""
    url = item.get('source_url') or item.get('url') or ''
    if isinstance(url, list):
        return url[0] if url else ''
    elif not isinstance(url, str):
        return str(url) if url else ''
    return url


def collect_data_type(ai_name, client, politician_id, politician_full, category_name, data_type, topic_mode, target_count):
    """ê³µì‹/ê³µê°œ ë°ì´í„° í†µí•© ìˆ˜ì§‘ í•¨ìˆ˜ (ìµœëŒ€ 5íšŒ ì¬ì‹œë„)

    Args:
        politician_id: ì •ì¹˜ì¸ ID (DB ì¤‘ë³µ í™•ì¸ìš©)
        topic_mode: 'negative' (ë¶€ì •), 'positive' (ê¸ì •), 'free' (ììœ )
    """
    # âœ… V30 ëª©í‘œ ìˆ˜ëŸ‰ ì´ˆê³¼ ë°©ì§€: DB í™•ì¸ í›„ ë¶€ì¡±í•œ ë§Œí¼ë§Œ ìˆ˜ì§‘
    try:
        # topic_modeë¥¼ DB sentimentë¡œ ë³€í™˜
        db_sentiment = topic_mode_to_sentiment(topic_mode)

        existing = supabase.table(TABLE_COLLECTED_DATA)\
            .select('*', count='exact')\
            .eq('politician_id', politician_id)\
            .eq('category', category_name.lower())\
            .eq('data_type', data_type)\
            .eq('collector_ai', ai_name)\
            .eq('sentiment', db_sentiment)\
            .execute()

        existing_count = existing.count or 0

        if existing_count >= target_count:
            print(f"    â„¹ï¸ ì´ë¯¸ {existing_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ (ëª©í‘œ: {target_count}ê°œ) - ê±´ë„ˆëœ€")
            return []

        # ë¶€ì¡±í•œ ë§Œí¼ë§Œ ìˆ˜ì§‘
        actual_target = target_count - existing_count
        print(f"    ğŸ“Š ê¸°ì¡´ {existing_count}ê°œ / ëª©í‘œ {target_count}ê°œ â†’ {actual_target}ê°œ ì¶”ê°€ ìˆ˜ì§‘")
    except Exception as e:
        print(f"    âš ï¸ DB ì²´í¬ ì‹¤íŒ¨, ì „ì²´ ìˆ˜ì§‘ ì§„í–‰: {e}")
        actual_target = target_count

    MAX_RETRIES = 5
    collected = []
    collected_urls = set()

    category_items = CATEGORY_ITEMS.get(category_name, [])
    if not category_items:
        category_items = [(f"í•­ëª©{i}", f"í‚¤ì›Œë“œ{i}") for i in range(1, 11)]

    # ë¼ìš´ë“œ ì„¤ì •
    if data_type == "official":
        round_configs = [
            ("2024-2025ë…„", "ìµœì‹  í™œë™"),
            ("2023ë…„", "ë²•ì•ˆ ë°œì˜"),
            ("2022-2023ë…„", "ê³µì‹ í™œë™"),
            ("ì˜ì •í™œë™", "êµ­íšŒ"),
            ("ì„±ê³¼ ì‹¤ì ", "ë°œí‘œ"),
        ]
    else:
        round_configs = [("", ""), ("ì¶”ê°€ê²€ìƒ‰", "")]  # ê³µê°œëŠ” 2ë¼ìš´ë“œ

    retry_count = 0

    while len(collected) < actual_target and retry_count < MAX_RETRIES:
        if retry_count > 0:
            print(f"    ğŸ”„ ì¬ì‹œë„ {retry_count}/{MAX_RETRIES} (í˜„ì¬ {len(collected)}ê°œ / ëª©í‘œ {actual_target}ê°œ)")

        for round_num, (year_hint, extra_keyword) in enumerate(round_configs, 1):
            if len(collected) >= actual_target:
                break

            if retry_count == 0:
                print(f"    [ë¼ìš´ë“œ {round_num}] í˜„ì¬ {len(collected)}ê°œ / ëª©í‘œ {actual_target}ê°œ")

            for item_name, item_keywords in category_items:
                if len(collected) >= actual_target:
                    break

                remaining = actual_target - len(collected)

                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = build_search_prompt(ai_name, data_type, topic_mode, politician_full, item_keywords, remaining, year_hint, extra_keyword)
                if not prompt:
                    continue

                # AI í˜¸ì¶œ
                result = call_ai(ai_name, client, prompt, data_type)

                added = 0
                if result:
                    items = parse_json_response(result)
                    for item in items:
                        if len(collected) >= actual_target:
                            break  # ëª©í‘œ ë„ë‹¬ ì¦‰ì‹œ ì¤‘ë‹¨!
                        if isinstance(item, dict):
                            url = extract_url(item)
                            if url and url not in collected_urls:
                                item['data_type'] = data_type
                                item['collector_ai'] = ai_name
                                item['sentiment'] = topic_mode_to_sentiment(topic_mode)  # DB ì €ì¥ìš© ë³€í™˜
                                collected.append(item)
                                collected_urls.add(url)
                                added += 1

                if added > 0 and retry_count == 0:
                    print(f"      [{item_name[:8]}] +{added}ê°œ â†’ ëˆ„ì  {len(collected)}ê°œ")
                time.sleep(0.3)

        # ëª©í‘œ ë¯¸ë‹¬ ì‹œ ì¬ì‹œë„
        if len(collected) < actual_target:
            retry_count += 1
        else:
            break

    # ëœë¤ ìƒ˜í”Œë§ (í†µê³„ì  ë¬´ì‘ìœ„ì„± í™•ë³´)
    if len(collected) > actual_target:
        return random.sample(collected, actual_target)
    else:
        return collected


def collect_with_ai(ai_name, politician_id, politician_name, category_idx, category_name, category_korean, test_mode=False):
    """íŠ¹ì • AIë¡œ ì¹´í…Œê³ ë¦¬ ë°ì´í„° ìˆ˜ì§‘ (ë¦¬íŒ©í† ë§ ë²„ì „)

    Args:
        test_mode: Trueì´ë©´ ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ (10ê°œë§Œ ìˆ˜ì§‘)
    """
    mode_label = "[TEST]" if test_mode else ""
    print(f"\n{'='*60}")
    print(f"{mode_label}[{ai_name}] {category_korean} ({category_name}) ìˆ˜ì§‘ ì‹œì‘")
    print(f"{'='*60}")

    # ì •ì¹˜ì¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë™ëª…ì´ì¸ êµ¬ë¶„ìš©)
    pol_info = get_politician_info(politician_id)
    politician_full = pol_info['search_string'] if pol_info['search_string'] else politician_name

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œë©´ TEST_SENTIMENT_DISTRIBUTION ì‚¬ìš©
    sentiment_dist = TEST_SENTIMENT_DISTRIBUTION[ai_name] if test_mode else SENTIMENT_DISTRIBUTION[ai_name]
    client = init_ai_client(ai_name)

    all_items = []

    # ê³µì‹ ë°ì´í„° ìˆ˜ì§‘ (20-20-60 ê· í˜•)
    if sentiment_dist["official"]["negative"] + sentiment_dist["official"]["positive"] + sentiment_dist["official"]["free"] > 0:
        print(f"  ğŸ“‹ ê³µì‹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        # ë¶€ì • OFFICIAL
        if sentiment_dist["official"]["negative"] > 0:
            neg_count = sentiment_dist["official"]["negative"]
            print(f"    ğŸš¨ ë¶€ì • {neg_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "official", "negative", neg_count
            )
            all_items.extend(collected)
            print(f"    âœ… ë¶€ì • {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        # ê¸ì • OFFICIAL
        if sentiment_dist["official"]["positive"] > 0:
            pos_count = sentiment_dist["official"]["positive"]
            print(f"    âœ¨ ê¸ì • {pos_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "official", "positive", pos_count
            )
            all_items.extend(collected)
            print(f"    âœ… ê¸ì • {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        # ììœ  OFFICIAL
        if sentiment_dist["official"]["free"] > 0:
            free_count = sentiment_dist["official"]["free"]
            print(f"    ğŸ² ììœ  {free_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "official", "free", free_count
            )
            all_items.extend(collected)
            print(f"    âœ… ììœ  {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    # ê³µê°œ ë°ì´í„° ìˆ˜ì§‘ (20-20-60 ê· í˜•)
    if sentiment_dist["public"]["negative"] + sentiment_dist["public"]["positive"] + sentiment_dist["public"]["free"] > 0:
        print(f"  ğŸ“° ê³µê°œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        # ë¶€ì • PUBLIC
        if sentiment_dist["public"]["negative"] > 0:
            neg_count = sentiment_dist["public"]["negative"]
            print(f"    ğŸš¨ ë¶€ì • {neg_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "public", "negative", neg_count
            )
            all_items.extend(collected)
            print(f"    âœ… ë¶€ì • {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        # ê¸ì • PUBLIC
        if sentiment_dist["public"]["positive"] > 0:
            pos_count = sentiment_dist["public"]["positive"]
            print(f"    âœ¨ ê¸ì • {pos_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "public", "positive", pos_count
            )
            all_items.extend(collected)
            print(f"    âœ… ê¸ì • {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        # ììœ  PUBLIC
        if sentiment_dist["public"]["free"] > 0:
            free_count = sentiment_dist["public"]["free"]
            print(f"    ğŸ² ììœ  {free_count}ê°œ...")
            collected = collect_data_type(
                ai_name, client, politician_id, politician_full, category_name, "public", "free", free_count
            )
            all_items.extend(collected)
            print(f"    âœ… ììœ  {len(collected)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    # DB ì €ì¥
    saved_count = 0
    skipped_count = 0  # ì¤‘ë³µ ìŠ¤í‚µ ì¹´ìš´íŠ¸

    for item in all_items:
        try:
            # ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì› (AIë§ˆë‹¤ ì‘ë‹µ í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            title = item.get('data_title') or item.get('title') or item.get('item') or ''
            content = item.get('data_content') or item.get('description') or item.get('content') or item.get('item') or ''
            source_url = item.get('source_url') or item.get('url') or item.get('link') or ''
            # URL íƒ€ì… ì²´í¬ (ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©)
            if isinstance(source_url, list):
                source_url = source_url[0] if source_url else ''
            elif not isinstance(source_url, str):
                source_url = str(source_url) if source_url else ''
            source_name = item.get('data_source') or item.get('source') or item.get('source_type') or ''
            raw_date = item.get('data_date') or item.get('date') or item.get('published_date')
            pub_date = normalize_date(raw_date)  # ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
            sentiment = item.get('sentiment') or 'free'  # sentiment added by collect_data_type()
            # âœ… 'free' ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€ (DBì—ì„œ í—ˆìš©ë¨)

            # titleì´ ì—†ìœ¼ë©´ content ì•ë¶€ë¶„ ì‚¬ìš©
            if not title and content:
                title = content[:50]

            collector = item.get('collector_ai', ai_name)

            # URL ì •ê·œí™” (ê³µë°± ì œê±°)
            source_url_normalized = str(source_url).strip() if source_url else ''

            # âœ… V30 ì¤‘ë³µ ì œê±°: ê°™ì€ AIê°€ ê°™ì€ URLì„ ì´ë¯¸ ìˆ˜ì§‘í–ˆëŠ”ì§€ í™•ì¸
            if source_url_normalized:  # URLì´ ìˆì„ ë•Œë§Œ ì²´í¬
                try:
                    existing = supabase.table(TABLE_COLLECTED_DATA)\
                        .select('id', count='exact')\
                        .eq('politician_id', politician_id)\
                        .eq('collector_ai', collector)\
                        .eq('source_url', source_url_normalized)\
                        .execute()

                    if existing.count and existing.count > 0:
                        # ì¤‘ë³µ ë°œê²¬ - skip
                        skipped_count += 1
                        continue
                except Exception as e:
                    # ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ì €ì¥ ì‹œë„)
                    print(f"  âš ï¸ ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜ ({source_url_normalized[:50]}...): {e}")
                    pass

            record = {
                'politician_id': politician_id,
                'politician_name': politician_name,
                'category': category_name.lower(),
                'data_type': item.get('data_type', 'public'),
                'collector_ai': collector,
                'title': str(title)[:200],
                'content': str(content)[:2000],
                'source_url': source_url_normalized,  # ì •ê·œí™”ëœ URL ì‚¬ìš©
                'source_name': str(source_name),
                'published_date': pub_date,
                'sentiment': sentiment,
                'is_verified': False
            }

            supabase.table(TABLE_COLLECTED_DATA).insert(record).execute()
            saved_count += 1
        except Exception as e:
            print(f"  âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    print(f"  ğŸ’¾ [{ai_name}] {category_korean}: {saved_count}ê°œ ì €ì¥, {skipped_count}ê°œ ì¤‘ë³µ ìŠ¤í‚µ")
    return saved_count


def parse_json_response(response_text):
    """JSON ì‘ë‹µ íŒŒì‹±"""
    if not response_text:
        return []

    try:
        # JSON ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # JSON ì§ì ‘ ì°¾ê¸° - ê°ì²´({}) ë˜ëŠ” ë°°ì—´([])
            obj_start = response_text.find('{')
            arr_start = response_text.find('[')

            if arr_start >= 0 and (obj_start < 0 or arr_start < obj_start):
                # ë°°ì—´ì´ ë¨¼ì € ë‚˜ì˜´
                start = arr_start
                end = response_text.rfind(']') + 1
            elif obj_start >= 0:
                # ê°ì²´ê°€ ë¨¼ì € ë‚˜ì˜´
                start = obj_start
                end = response_text.rfind('}') + 1
            else:
                return []

            if start >= 0 and end > start:
                json_str = response_text[start:end]
            else:
                return []

        # JSON íŒŒì‹±
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError:
            # json_repair ì‹œë„
            from json_repair import repair_json
            repaired = repair_json(json_str)
            data = json.loads(repaired)

        if isinstance(data, dict) and 'items' in data:
            return data['items']
        elif isinstance(data, list):
            return data
        else:
            return []

    except Exception as e:
        print(f"  âš ï¸ JSON íŒŒì‹± ì—ëŸ¬: {e}")
        return []


def collect_all_for_politician(politician_id, politician_name, target_ai=None, target_category=None, parallel=False, test_mode=False):
    """ì •ì¹˜ì¸ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘

    Args:
        test_mode: Trueì´ë©´ ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì¹´í…Œê³ ë¦¬ë‹¹ 10ê°œ, 3ê°œ AI ë³‘ë ¬)
    """
    mode_str = "[ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸]" if test_mode else ""
    target_per_cat = 10 if test_mode else 100

    print(f"\n{'#'*60}")
    print(f"# V30 {mode_str}ìˆ˜ì§‘ ì‹œì‘: {politician_name} ({politician_id})")
    print(f"# ë°°ë¶„: Gemini 90%, Grok 10% (Perplexity ì œê±°, Claude/ChatGPT ìˆ˜ì§‘ ì œì™¸)")
    print(f"# ì‹¤í–‰: Grok ìš°ì„  â†’ Gemini ë‚˜ì¤‘ (Grok ì¤‘ë³µ ìŠ¤í‚µ ë°©ì§€)")
    print(f"# ëª©í‘œ: ì¹´í…Œê³ ë¦¬ë‹¹ {target_per_cat}ê°œ")
    print(f"{'#'*60}")

    # ìˆ˜ì§‘ AI ëª©ë¡ (ë¹„ìš© ìµœì í™”: Claude/ChatGPT ì œì™¸, Perplexity ì œê±°)
    # Grok ìš°ì„  ì‹¤í–‰ (ì–‘ì´ ì ì–´ ë¨¼ì € ìˆ˜ì§‘ ì™„ë£Œ í›„ Gemini ì‹¤í–‰)
    collect_ais = ["Grok", "Gemini"]  # Perplexity ì œê±° (401 ì—ëŸ¬ + ë¹„ìš© í­íƒ„)
    if target_ai:
        collect_ais = [target_ai]

    # ì¹´í…Œê³ ë¦¬ ëª©ë¡
    categories = CATEGORIES
    if target_category:
        categories = [CATEGORIES[target_category - 1]]

    total_saved = 0
    start_time = time.time()

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë˜ëŠ” parallel í”Œë˜ê·¸ë©´ í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰
    if parallel or test_mode:
        # ===== V30 í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í–‰: Grok ìš°ì„  â†’ Gemini ë‚˜ì¤‘ =====
        # ì´ìœ : Grokì´ "ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œ" íŒë‹¨ìœ¼ë¡œ ê±´ë„ˆë›°ëŠ” ë¬¸ì œ ë°©ì§€
        print(f"\n[ìˆœì°¨ ì‹¤í–‰] Grok ìš°ì„  â†’ Gemini ë‚˜ì¤‘ (ì´ {len(collect_ais)} AIs Ã— {len(categories)} ì¹´í…Œê³ ë¦¬)")

        failed_tasks = []

        # ===== 1ë‹¨ê³„: Grok ë¨¼ì € ì‹¤í–‰ (ëª¨ë“  ì¹´í…Œê³ ë¦¬) =====
        for ai_name in collect_ais:
            print(f"\n{'='*60}")
            print(f"[{ai_name}] ìˆ˜ì§‘ ì‹œì‘")
            print(f"{'='*60}")

            for cat_idx, (cat_name, cat_korean) in enumerate(categories):
                try:
                    count = collect_with_ai(
                        ai_name, politician_id, politician_name,
                        cat_idx, cat_name, cat_korean, test_mode
                    )
                    total_saved += count
                except Exception as e:
                    print(f"  âŒ [{ai_name}] {cat_korean} 1ì°¨ ì‹¤íŒ¨: {e}")
                    failed_tasks.append({
                        'ai_name': ai_name,
                        'cat_idx': cat_idx,
                        'cat_name': cat_name,
                        'cat_korean': cat_korean
                    })

            print(f"\nâœ… [{ai_name}] ìˆ˜ì§‘ ì™„ë£Œ")

            # AI ê°„ ê°„ê²©
            if ai_name != collect_ais[-1]:
                time.sleep(2)

        # ===== 2ì°¨: ì‹¤íŒ¨í•œ ì‘ì—…ë§Œ ìˆœì°¨ ì¬ì‹œë„ (ì•ˆì „) =====
        if failed_tasks:
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì‹œë„ ì‹œì‘: {len(failed_tasks)}ê°œ")
            print(f"{'='*60}")

            for attempt in range(1, 4):  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
                if not failed_tasks:
                    break

                print(f"\n[ì¬ì‹œë„ {attempt}/3] {len(failed_tasks)}ê°œ ì‘ì—…")
                retry_success = []

                for task in failed_tasks:
                    try:
                        # Exponential backoff
                        backoff_time = 2 ** (attempt - 1)
                        if backoff_time > 1:
                            time.sleep(backoff_time)

                        count = collect_with_ai(
                            task['ai_name'], politician_id, politician_name,
                            task['cat_idx'], task['cat_name'], task['cat_korean'], test_mode
                        )
                        total_saved += count
                        retry_success.append(task)
                        print(f"  âœ… [{task['ai_name']}] {task['cat_korean']} ì¬ì‹œë„ ì„±ê³µ (+{count}ê°œ)")
                    except Exception as e:
                        print(f"  âš ï¸ [{task['ai_name']}] {task['cat_korean']} ì¬ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")

                # ì„±ê³µí•œ ì‘ì—… ì œê±°
                failed_tasks = [t for t in failed_tasks if t not in retry_success]

            # ===== 3ì°¨: ìµœì¢… ì‹¤íŒ¨ ë¡œê¹… =====
            if failed_tasks:
                print(f"\n{'='*60}")
                print(f"âŒ ìµœì¢… ì‹¤íŒ¨ ì‘ì—…: {len(failed_tasks)}ê°œ")
                print(f"{'='*60}")
                for task in failed_tasks:
                    print(f"  - [{task['ai_name']}] {task['cat_korean']} ({task['cat_name']})")
                print(f"\nâš ï¸ ì¼ë¶€ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì‹¤íŒ¨. ì¬ìˆ˜ì§‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        # ìˆœì°¨ ìˆ˜ì§‘
        for cat_idx, (cat_name, cat_korean) in enumerate(categories):
            for ai_name in collect_ais:
                count = collect_with_ai(
                    ai_name, politician_id, politician_name,
                    cat_idx, cat_name, cat_korean, test_mode
                )
                total_saved += count
                time.sleep(1)  # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€

    elapsed = time.time() - start_time

    print(f"\n{'='*60}")
    print(f"âœ… V30 {mode_str}ìˆ˜ì§‘ ì™„ë£Œ: {politician_name}")
    print(f"   ì´ ì €ì¥: {total_saved}ê°œ")
    print(f"   ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
    print(f"{'='*60}")

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œë©´ ê²€ì¦ ê²°ê³¼ ì¶œë ¥
    if test_mode:
        verify_test_results(politician_id, politician_name, categories)

    return total_saved


def verify_test_results(politician_id, politician_name, categories):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦: {politician_name}")
    print(f"{'='*60}")

    total_by_ai = {"Gemini": 0, "Grok": 0}
    total_by_type = {"official": 0, "public": 0}

    for cat_name, cat_korean in categories:
        # AIë³„ ìˆ˜ì§‘ ê°œìˆ˜ ì¡°íšŒ
        for ai_name in ["Gemini", "Grok"]:
            count = get_exact_count(TABLE_COLLECTED_DATA, {
                'politician_id': politician_id,
                'category': cat_name,
                'collector_ai': ai_name
            })
            total_by_ai[ai_name] += count

        # ë°ì´í„° íƒ€ì…ë³„ ì¡°íšŒ
        for dtype in ["official", "public"]:
            count = get_exact_count(TABLE_COLLECTED_DATA, {
                'politician_id': politician_id,
                'category': cat_name,
                'data_type': dtype
            })
            total_by_type[dtype] += count

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“ˆ AIë³„ ìˆ˜ì§‘ ê²°ê³¼:")
    total = sum(total_by_ai.values())
    for ai_name, count in total_by_ai.items():
        pct = (count / total * 100) if total > 0 else 0
        expected = TEST_DISTRIBUTION[ai_name]['total'] * len(categories)
        status = "âœ…" if count >= expected * 0.8 else "âš ï¸"
        print(f"   {status} {ai_name}: {count}ê°œ ({pct:.1f}%) - ëª©í‘œ {expected}ê°œ")

    print(f"\nğŸ“ˆ ë°ì´í„° íƒ€ì…ë³„:")
    for dtype, count in total_by_type.items():
        print(f"   â€¢ {dtype.upper()}: {count}ê°œ")

    print(f"\nğŸ“ˆ ì´í•©: {total}ê°œ")

    # ë¹„ìœ¨ ê²€ì¦
    if total > 0:
        gemini_pct = total_by_ai["Gemini"] / total * 100
        perplexity_pct = total_by_ai["Perplexity"] / total * 100
        grok_pct = total_by_ai["Grok"] / total * 100

        print(f"\nğŸ¯ ë¹„ìœ¨ ê²€ì¦ (ëª©í‘œ: 60-30-10):")
        print(f"   Gemini: {gemini_pct:.1f}% {'âœ…' if 50 <= gemini_pct <= 70 else 'âš ï¸'}")
        print(f"   Perplexity: {perplexity_pct:.1f}% {'âœ…' if 20 <= perplexity_pct <= 40 else 'âš ï¸'}")
        print(f"   Grok: {grok_pct:.1f}% {'âœ…' if 5 <= grok_pct <= 20 else 'âš ï¸'}")

    print(f"{'='*60}")


def get_all_politicians():
    """DBì—ì„œ ì „ì²´ ì •ì¹˜ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        result = supabase.table('politicians').select('id, name').execute()
        return result.data if result.data else []
    except Exception as e:
        print(f"âŒ ì •ì¹˜ì¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def collect_all_politicians(target_ai=None, target_category=None, parallel=False, test_mode=False):
    """ì „ì²´ ì •ì¹˜ì¸ ì¼ê´„ ìˆ˜ì§‘"""
    politicians = get_all_politicians()

    if not politicians:
        print("âŒ ìˆ˜ì§‘í•  ì •ì¹˜ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    mode_str = "[ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸]" if test_mode else ""
    print(f"\n{'#'*60}")
    print(f"# V30 {mode_str}ì „ì²´ ì •ì¹˜ì¸ ì¼ê´„ ìˆ˜ì§‘")
    print(f"# ì´ {len(politicians)}ëª…")
    print(f"{'#'*60}\n")

    success_count = 0
    fail_count = 0

    for i, p in enumerate(politicians, 1):
        pid = p['id']
        pname = p['name']

        print(f"\n[{i}/{len(politicians)}] {pname} ({pid}) ìˆ˜ì§‘ ì‹œì‘...")

        try:
            saved = collect_all_for_politician(
                pid, pname,
                target_ai=target_ai,
                target_category=target_category,
                parallel=parallel,
                test_mode=test_mode
            )
            success_count += 1
            print(f"âœ… {pname}: {saved}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as e:
            fail_count += 1
            print(f"âŒ {pname}: ìˆ˜ì§‘ ì‹¤íŒ¨ - {e}")

        # ì •ì¹˜ì¸ ê°„ ê°„ê²© (API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€)
        if i < len(politicians):
            time.sleep(2 if not test_mode else 1)

    print(f"\n{'#'*60}")
    print(f"# {mode_str}ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"# ì„±ê³µ: {success_count}ëª…, ì‹¤íŒ¨: {fail_count}ëª…")
    print(f"{'#'*60}")


def main():
    parser = argparse.ArgumentParser(description='V30 3ê°œ AI ë¶„ë‹´ ì›¹ê²€ìƒ‰ ìˆ˜ì§‘ (ë¹„ìš© ìµœì í™”)')
    parser.add_argument('--politician_id', help='ì •ì¹˜ì¸ ID (--allê³¼ í•¨ê»˜ ì‚¬ìš© ë¶ˆê°€)')
    parser.add_argument('--politician_name', help='ì •ì¹˜ì¸ ì´ë¦„ (--allê³¼ í•¨ê»˜ ì‚¬ìš© ë¶ˆê°€)')
    parser.add_argument('--all', action='store_true', help='ì „ì²´ ì •ì¹˜ì¸ ì¼ê´„ ìˆ˜ì§‘')
    parser.add_argument('--ai', choices=['Gemini', 'Perplexity', 'Grok'], help='íŠ¹ì • AIë§Œ ì‹¤í–‰ (Claude/ChatGPT ì œì™¸)')
    parser.add_argument('--category', type=int, choices=range(1, 11), help='íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ (1-10)')
    parser.add_argument('--parallel', action='store_true', help='ë³‘ë ¬ ì‹¤í–‰')
    parser.add_argument('--test', action='store_true', help='ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì¹´í…Œê³ ë¦¬ë‹¹ 10ê°œ, 3ê°œ AI ë³‘ë ¬, ìë™ ê²€ì¦)')
    parser.add_argument('--skip-validation', action='store_true', help='ìˆ˜ì§‘ í›„ ìë™ ê²€ì¦ ê±´ë„ˆë›°ê¸°')

    args = parser.parse_args()

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì•ˆë‚´
    if args.test:
        print(f"\n{'='*60}")
        print(f"ğŸ§ª ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”")
        print(f"   â€¢ ì¹´í…Œê³ ë¦¬ë‹¹ 10ê°œ (ì „ì²´ 100ê°œ ëŒ€ì‹ )")
        print(f"   â€¢ 3ê°œ AI ë³‘ë ¬ ì‹¤í–‰ (Gemini 6 + Perplexity 3 + Grok 1)")
        print(f"   â€¢ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3-5ë¶„ (1ê°œ ì¹´í…Œê³ ë¦¬)")
        print(f"   â€¢ ì™„ë£Œ í›„ ìë™ ê²€ì¦")
        print(f"{'='*60}\n")

    # ì „ì²´ ì •ì¹˜ì¸ ì¼ê´„ ìˆ˜ì§‘
    if args.all:
        collect_all_politicians(
            target_ai=args.ai,
            target_category=args.category,
            parallel=args.parallel or args.test,
            test_mode=args.test
        )
        return

    # ê°œë³„ ì •ì¹˜ì¸ ìˆ˜ì§‘ (ê¸°ì¡´ ë°©ì‹)
    if not args.politician_id or not args.politician_name:
        print("âŒ --politician_idì™€ --politician_nameì„ ì§€ì •í•˜ê±°ë‚˜, --allì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        print("")
        print("ğŸ“‹ ì‚¬ìš© ì˜ˆì‹œ:")
        print("   # ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ (ì¹´í…Œê³ ë¦¬ 1ê°œ, 3-5ë¶„)")
        print("   python collect_v30.py --politician_id=xxx --politician_name=\"í™ê¸¸ë™\" --test --category=1")
        print("")
        print("   # ì „ì²´ ìˆ˜ì§‘ (ë³‘ë ¬)")
        print("   python collect_v30.py --politician_id=xxx --politician_name=\"í™ê¸¸ë™\" --parallel")
        print("")
        print("   # ì „ì²´ ì •ì¹˜ì¸ ì¼ê´„")
        print("   python collect_v30.py --all --parallel")
        return

    # ì •ì¹˜ì¸ í™•ì¸
    exists, db_name = check_politician_exists(args.politician_id)
    if not exists:
        print(f"âŒ ì •ì¹˜ì¸ ID '{args.politician_id}'ê°€ politicians í…Œì´ë¸”ì— ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € ì •ì¹˜ì¸ì„ ë“±ë¡í•˜ì„¸ìš”.")
        return

    # ìˆ˜ì§‘ ì‹¤í–‰
    collect_all_for_politician(
        args.politician_id,
        args.politician_name,
        target_ai=args.ai,
        target_category=args.category,
        parallel=args.parallel or args.test,
        test_mode=args.test
    )

    # ìë™ ê²€ì¦ íŠ¸ë¦¬ê±° (ì˜µì…˜ 1: ë©”ì¸ ì—ì´ì „íŠ¸ ë°©ì‹)
    if not args.skip_validation:
        print(f"\n{'='*60}")
        print("ğŸ” ìë™ ê²€ì¦ ì‹œì‘...")
        print("ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.")
        print(f"{'='*60}\n")

        try:
            # validate_v30.pyì˜ run_validation_pipeline í•¨ìˆ˜ ì„í¬íŠ¸
            import sys
            import os
            script_dir = os.path.dirname(os.path.abspath(__file__))
            sys.path.insert(0, script_dir)

            from validate_v30 import run_validation_pipeline

            # ê²€ì¦ ì‹¤í–‰
            result = run_validation_pipeline(
                politician_id=args.politician_id,
                politician_name=args.politician_name,
                mode='all',
                ai_name=args.ai
            )

            print(f"\n{'='*60}")
            print("âœ… ìë™ ê²€ì¦ ì™„ë£Œ")
            print(f"   â€¢ ìœ íš¨: {result.get('valid', 0)}ê°œ")
            print(f"   â€¢ ë¬´íš¨: {result.get('invalid', 0)}ê°œ")
            print(f"{'='*60}\n")

        except Exception as e:
            print(f"\nâš ï¸ ìë™ ê²€ì¦ ì‹¤íŒ¨: {e}")
            print("ìˆ˜ë™ìœ¼ë¡œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            print(f"python validate_v30.py --politician_id={args.politician_id} --politician_name=\"{args.politician_name}\"")


if __name__ == "__main__":
    main()
