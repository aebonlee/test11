# -*- coding: utf-8 -*-
"""
ìˆ˜ì§‘ ë°ì´í„° ë‚ ì§œ ë¶„í¬ ë¶„ì„
"""

import os
import sys
from collections import Counter
from datetime import datetime
from supabase import create_client
from dotenv import load_dotenv

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_ROLE_KEY')
)

TABLE_COLLECTED = "collected_data_v30"

def analyze_dates(politician_id, category_name, category_korean):
    """ë‚ ì§œ ë¶„í¬ ë¶„ì„"""
    print(f"\n{'='*80}")
    print(f"ğŸ“… {category_korean} ({category_name}) ìˆ˜ì§‘ ë°ì´í„° ë‚ ì§œ ë¶„ì„")
    print(f"{'='*80}\n")

    # ë°ì´í„° ì¡°íšŒ
    result = supabase.table(TABLE_COLLECTED).select('*').eq(
        'politician_id', politician_id
    ).eq('category', category_name.lower()).execute()

    if not result.data:
        print("ìˆ˜ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    data = result.data
    print(f"ì´ ìˆ˜ì§‘ ë°ì´í„°: {len(data)}ê°œ\n")

    # ë‚ ì§œ íŒŒì‹± ë° ë¶„ì„
    dates = []
    no_date = 0

    for item in data:
        pub_date = item.get('published_date')
        if pub_date and pub_date != 'N/A':
            try:
                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                if 'T' in pub_date:
                    date_obj = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                else:
                    date_obj = datetime.strptime(pub_date, '%Y-%m-%d')
                dates.append(date_obj)
            except:
                no_date += 1
        else:
            no_date += 1

    if no_date > 0:
        print(f"âš ï¸ ë‚ ì§œ ì—†ìŒ: {no_date}ê°œ\n")

    if not dates:
        print("ë¶„ì„ ê°€ëŠ¥í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì—°ë„ë³„ ë¶„í¬
    print(f"{'â”€'*80}")
    print(f"ğŸ“Š ì—°ë„ë³„ ë¶„í¬")
    print(f"{'â”€'*80}\n")

    years = Counter([d.year for d in dates])
    for year in sorted(years.keys(), reverse=True):
        count = years[year]
        pct = (count / len(dates) * 100) if dates else 0
        print(f"  {year}ë…„: {count:3d}ê°œ ({pct:5.1f}%)")

    # ì—°ë„-ì›”ë³„ ìƒì„¸ ë¶„í¬
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Š ìµœê·¼ 2ë…„ ì›”ë³„ ë¶„í¬")
    print(f"{'â”€'*80}\n")

    recent_dates = [d for d in dates if d.year >= 2024]
    if recent_dates:
        year_months = Counter([f"{d.year}-{d.month:02d}" for d in recent_dates])
        for ym in sorted(year_months.keys(), reverse=True):
            count = year_months[ym]
            pct = (count / len(recent_dates) * 100) if recent_dates else 0
            print(f"  {ym}: {count:3d}ê°œ ({pct:5.1f}%)")

    # ìµœì‹ /ìµœêµ¬ ë‚ ì§œ
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Š ë‚ ì§œ ë²”ìœ„")
    print(f"{'â”€'*80}\n")

    oldest = min(dates)
    newest = max(dates)
    print(f"  ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„°: {oldest.strftime('%Y-%m-%d')}")
    print(f"  ê°€ì¥ ìµœì‹  ë°ì´í„°: {newest.strftime('%Y-%m-%d')}")
    print(f"  ìˆ˜ì§‘ ê¸°ê°„: {(newest - oldest).days}ì¼")

    # sentimentë³„ ë‚ ì§œ ë¶„í¬
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Š sentimentë³„ í‰ê·  ë‚ ì§œ")
    print(f"{'â”€'*80}\n")

    sentiment_dates = {}
    for item in data:
        sentiment = item.get('sentiment', 'unknown')
        pub_date = item.get('published_date')
        if pub_date and pub_date != 'N/A':
            try:
                if 'T' in pub_date:
                    date_obj = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                else:
                    date_obj = datetime.strptime(pub_date, '%Y-%m-%d')
                if sentiment not in sentiment_dates:
                    sentiment_dates[sentiment] = []
                sentiment_dates[sentiment].append(date_obj)
            except:
                pass

    for sentiment in ['positive', 'negative', 'free']:
        if sentiment in sentiment_dates:
            avg_date = sum([d.timestamp() for d in sentiment_dates[sentiment]]) / len(sentiment_dates[sentiment])
            avg_date_obj = datetime.fromtimestamp(avg_date)
            count = len(sentiment_dates[sentiment])
            print(f"  {sentiment:10s}: {avg_date_obj.strftime('%Y-%m-%d')} (í‰ê· , {count}ê°œ)")

    # ìµœê·¼ ë…¼ë€ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
    print(f"\n{'â”€'*80}")
    print(f"ğŸ” ìµœê·¼ ë…¼ë€ ê´€ë ¨ ë°ì´í„° (2024-2025)")
    print(f"{'â”€'*80}\n")

    keywords = ['ëª…íƒœê· ', 'ë‡Œë¬¼', 'íš¡ë ¹', 'ê²½ì„ ', 'ë¶ˆë²•', 'ì—¬ë¡ ì¡°ì‚¬', 'ì†Œí™˜', 'ì˜í˜¹']
    recent_controversy = []

    for item in data:
        pub_date = item.get('published_date')
        title = item.get('title', '')
        content = item.get('content', '')

        if pub_date:
            try:
                if 'T' in pub_date:
                    date_obj = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                else:
                    date_obj = datetime.strptime(pub_date, '%Y-%m-%d')

                if date_obj.year >= 2024:
                    for keyword in keywords:
                        if keyword in title or keyword in content:
                            recent_controversy.append({
                                'date': date_obj,
                                'keyword': keyword,
                                'title': title,
                                'sentiment': item.get('sentiment', 'unknown')
                            })
                            break
            except:
                pass

    if recent_controversy:
        print(f"ë…¼ë€ ê´€ë ¨ ë°ì´í„°: {len(recent_controversy)}ê°œ\n")

        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
        recent_controversy.sort(key=lambda x: x['date'], reverse=True)
        for item in recent_controversy[:10]:
            date_str = item['date'].strftime('%Y-%m-%d')
            keyword = item['keyword']
            sentiment = item['sentiment']
            title = item['title'][:80]
            print(f"  [{date_str}] [{sentiment:8s}] {keyword}: {title}...")
    else:
        print("ë…¼ë€ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def main():
    import argparse

    parser = argparse.ArgumentParser(description='ìˆ˜ì§‘ ë°ì´í„° ë‚ ì§œ ë¶„í¬ ë¶„ì„')
    parser.add_argument('--politician_id', required=True, help='ì •ì¹˜ì¸ ID')
    parser.add_argument('--categories', nargs='+', required=True, help='ì¹´í…Œê³ ë¦¬ ëª©ë¡')
    args = parser.parse_args()

    category_map = {
        'integrity': 'ì²­ë ´ì„±',
        'ethics': 'ìœ¤ë¦¬ì„±',
        'expertise': 'ì „ë¬¸ì„±',
        'leadership': 'ë¦¬ë”ì‹­',
        'vision': 'ë¹„ì „',
        'accountability': 'ì±…ì„ê°',
        'transparency': 'íˆ¬ëª…ì„±',
        'communication': 'ì†Œí†µëŠ¥ë ¥',
        'responsiveness': 'ëŒ€ì‘ì„±',
        'publicinterest': 'ê³µìµì„±'
    }

    for category in args.categories:
        korean_name = category_map.get(category, category)
        analyze_dates(args.politician_id, category, korean_name)

if __name__ == "__main__":
    main()
